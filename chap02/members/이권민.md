# 가상 면접 사례로 배우는 대규모 시스템 설계 기초(2장 + 캐시)

스터디 날짜: 2025년 6월 19일

# 2장 - 개략적인 규모 추정

## 2의 제곱수

아스키 문자 하나는 1 Byte이다.

![Image](https://github.com/user-attachments/assets/6b27f68f-c181-470b-b9fa-3a1f008da76d)

## 모든 프로그래머가 알아야 하는 응답지연 값

![Image](https://github.com/user-attachments/assets/2b8444d6-6a62-4f67-ab6d-72162a440a74)

# 캐시

캐싱 전략을 개발할 때 중요한 것

- 데이터 일관성
    - 데이터가 항상 최신이고 정확함을 목표
- 캐시 무효화 매커니즘
    - 데이터가 업데이트 될 때, 캐시에서 이전 데이터는 삭제되고 새 데이터를 가져오도록

## 캐시가 왜 필요할까?

우선 캐시가 무엇인지에 대해 알아야 할 필요가 있다.

캐시란? 자주 쓰는 데이터를 더 빠른 저장 공간(주로 메모리)에 미리 두고 꺼내 쓰는 기법이다.

**자주 쓰는 데이터**, **더 빠른 저장 공간**이 핵심이다.

- 자주 쓰지 않는 데이터를 캐싱 해봤자 의미가 없다.
- 느린 저장 공간, 예를 들어 SSD에 저장을 한다면 의미가 없다.

이처럼 자주 쓰는 데이터에 대해서는 추가적인 연산을 하지 않고, 빠른 저장 공간에 저장하여 시스템의 **성능**과 **안정성**을 크게 개선할 수 있다.

예를 들어 사용자별 대시보드, 추천 리스트, 상품 목록 등은 자주 바뀌지 않으면서도 조회 빈도가 높다.

## 캐시의 효능

### 1. 응답 속도 단축

SSD에서 조회하는 것보다 메모리에 접근하는 것이 훨씬 빠르다.(약 수백 ~ 수천 배)

DB에서 조회 횟수를 줄이는 것만으로도 성능을 높일 수 있다.

### 2. DB 부하 감소

읽기 작업을 캐시가 대신 받아준다면 DB에 가는 부하가 감소한다. 자연스럽게 scale up 또는 scale out에 들어가는 비용이 줄어든다.

## 캐시의 분류

### 위치에 따른 캐시 분류

| 위치 | 설명 | 예시 |
| --- | --- | --- |
| 클라이언트 | 사용자 디바이스에 저장 | 브라우저 캐시, 쿠키, service worker 등 |
| 엣지 | 사용자와 가까운 CDN 노드에 저장 | CloudFront, Akamai |
| 서버 | API 응답이나 DB 결과를 메모리에 저장 | Spring Cache, LocalMap, Ehcache |
| 분산 캐시 | 네트워크 상에서 여러 인스턴스가 공유 | Redis, Memcached |

## 캐싱 전략 - 읽기

### 1. Cache-aside (Lazy-loading)

클라이언트가 데이터 요청 → 없으면 → DB에서 조회 후 캐시에 저장

**장점**

- 사용된 데이터만 캐시에 올라간다.
- 구현이 단순하고 유연하다.

**단점**

- 처음 조회시에는 캐시가 비어있어서 DB에 다녀와야한다.(cold start)
- 캐시 무효화 등 수동 처리가 필요하다.

---

### 2. Read-through

애플리케이션은 캐시에만 요청 → 없으면 → 캐시가 자동으로 DB 조회 후 응답

**장점**

- 개발자가 캐시 miss를 처리할 필요 없다.
- 캐시와 DB가 분리되어 있다는 것을 애플리케이션이 알지 않아도 된다.

**단점**

- 캐시 레이어에 DB 접근 권한이 필요하다.
- 아키텍처의 로직이 복잡하고 외부 캐시 솔루션에 의존한다.

---

### 3. Pre-warming (Warm-up)

이벤트 전 미리 캐시에 적재

**장점**

- cold start를 방지한다.
- 마케팅 이후 트래픽 급증을 대비할 수 있다.

**단점**

- 캐시 메모리 낭비 가능성이 있다.
- TTL과 데이터 변경 시점이 맞지 않으면 stale data가 발생한다.
    - stale data란? 최신 데이터가 아니거나 유효하지 않은 데이터를 의미한다.

## 캐싱 전략 - 쓰기

### 1. Write-through

데이터를 캐시에 먼저 저장 → 동시에 DB에 반영

**장점**

- 데이터 정합성을 확보할 수 있다.
- 캐시는 항상 최신의 데이터 상태를 유지한다.

**단점**

- 쓰기 속도가 느리다.
- 쓰기 횟수 많을수록 비효율적이다.

---

### 2. Write-around

쓰기 시에는 캐시 X → 다음 읽기 시에 캐시 miss → DB에서 읽고 캐시에 저장

- cache aside랑은 다른 게 없는 것 같다. 그저 관점의 차이?

**장점**

- 사용되지 않은 데이터 저장을 방지한다.
- 쓰기 성능이 향상된다.

**단점**

- cold start를 하게 된다.
- cache hit rate가 낮아질 수 있다.

---

### 3. Write-back

캐시에 작성 → 별도의 쓰기 큐/스레드가 추가적으로 DB에 반영

**장점**

- 쓰기 속도가 매우 빠르다.
- DB에 가는 부담이 감소한다.

**단점**

- 장애 발생 시 데이터 유실의 위험이 있다.
- DB와 캐시가 일시적으로 불일치할 수 있다.

추가) 같은 트래픽을 받더라도 메모리가 DB의 I/O 작업보다 훨씬 빠르기 때문에 충분히 소화할 수 있다.

## 단일 캐시 일관성

캐시를 사용하게 되면 일관성이 깨진다. 무엇에 대한 일관성일까?

- 캐시에 있는 데이터와 DB에 있는 데이터 간의 일관성이다.

그렇다면 왜 깨지는 것일까?

- 캐시 데이터는 실시간 DB 데이터와 ‘시간차’가 있다. DB에는 값을 변경했지만, 캐시는 예전 값을 유지하고 있을 수 있다.
- 예를 들어서 적절히 캐시의 데이터를 없애주지 않는다면, cache-aside 전략에서는 cache hit이 계속 나기 때문에 새로운 데이터를 받아오지 않는다.

### 일관성 문제 해결 방법

캐시 무효화 (Invalidation)

- 더 이상 유효하지 않은 데이터를 제거한다.
- 데이터 변경 등 **외부 이벤트**에 의해서 일어난다.
- 방법
    - TTL: 일정 시간이 지나면 자동으로 삭제 된다.
    - 수동 Invalidation: 대상을 코드를 통해서 명시적으로 지정한다.
        
        ```java
        @CacheEvict(value = "user", key = "#user.id")
        public void updateUser(User user) {
            userRepository.save(user);
        }
        ```
        
- 정합성을 위해 일부 데이터를 삭제하게 된다.
- 캐시 무효화를 사용하면 개발자가 원하는 시점에 캐시를 제거할 수 있다. 이로 인해 정합성을 보장하게 된다.
- 하지만, 무효화 누락이 되면 stale data가 노출된다.
    - 무효화 누락이 될 수 있나? 무효화 누락은 상황을 제대로 커버하지 못했을 때 발생한다.
        - 수동 Invalidation만 사용하는 경우, evict를 하지 않는다면 누락될 수 있다.
        - TTL을 사용한다고 하더라도, 설정한 TTL보다 더 자주 데이터가 바뀌게 된다면 stale data가 노출될 수 있다.

### 일관성과 직접적인 관련은 없지만 함께 나오는 Eviction

Eviction

- 캐시 공간이 부족해졌을 때, **자동으로** 특정 데이터를 제거하는 것이다.
- 캐시는 메모리 기반의 저장소이다. 그렇기 때문에 SSD나 HDD에 비해서 용량에 한계가 존재한다.
- Eviction algorithm
    - LRU
    - LFU
    - FIFO
    - Random

## 분산 캐시 일관성

### 캐시 일관성 문제가 발생하는 대표적 시나리오

1. Write - Invalidation race condition
    
    초기 조건: cache:user:1 → ‘Alice’ 인 상태
    
    ![Image](https://github.com/user-attachments/assets/6f899839-1fad-45aa-8779-90669ff19bbd)
    
2. Write - Write 충돌 (Lost Update)
    
    두 개의 메서드가 동시에 DB와 Cache를 갱신하면, 한 쪽의 갱신이 무시되는 상황이 생길 수 있다.
    

### 해결 방법

1. 분산 락(Distributed Lock)
    
    Redis 같은 경우는 [Redlock 알고리즘](https://medium.com/sjk5766/redis%EA%B0%80-%EC%A0%9C%EA%B3%B5%ED%95%98%EB%8A%94-redlock%EC%9D%84-%EC%95%8C%EC%95%84%EB%B3%B4%EC%9E%90-2feb7278411e)을 이용해 동시성 제어를 할 수 있다.
    
2. [Double Delete](https://stackoverflow.com/questions/63520180/implementing-double-delete-caching-with-c-sharp)
    
    말 그대로 cache 무효화를 두 번 하는 것이다.
    
    DB에 create나 update 직후 관련된 데이터를 cache에서 무효화 한다.
    
    일정 시간이 지난 후에 다시 한 번 cache에서 무효화 한다.
    
    이렇게 하면 그 사이에 누군가 stale data를 만든다고 하더라도 무효화할 수 있다.
    
3. Write through
    
    일관성은 높지만 쓰기 성능이 떨어진다.
    
4. Versioning / ETag
    
    데이터에 버전 번호나 해시를 부여하여 업데이트 시 버전을 비교한다.
    
5. Pub/Sub / 메시지 큐 기반 무효화 전파
    
    데이터 변경시 업데이트 이벤트를 발행 시킨다.
    
    모든 애플리케이션에서 해당 정보를 구독하고 관련된 key를 즉시 삭제한다.
    

### 그 외의 캐시 문제

**Cache Stampede**

- 일정 시점에 동일 키의 TTL 만료 시에 대량의 요청이 한꺼번에 DB로 몰려 DB 과부하가 생긴다.
    
    보통 이 경우의 키는 Hot Key라고 하며, Hot key는 요청이 자주 오는 key를 의미한다.
    
    Cache Stampede 방지
    
    - Mutex Key
        - 첫 요청만 DB 조회 후 캐시 재생성, 나머지는 기다리게 함
    - [Early Refill](https://toss.tech/article/cache-traffic-tip#:~:text=%EA%B3%A0%EB%AF%BC%ED%95%A0%20%ED%95%84%EC%9A%94%EA%B0%80%20%EC%9E%88%EC%8A%B5%EB%8B%88%EB%8B%A4.-,4.%20%ED%95%AB(Hotkey)%20%EB%A7%8C%EB%A3%8C,-%EB%A7%8E%EC%9D%80%20%EC%9A%94%EC%B2%AD%EC%9D%B4%20%EC%A7%91%EC%A4%91%EB%90%98%EB%8A%94)
        - TTL 만료 직전 백그라운드에서 미리 재생성
    - [Randomized TTL](https://toss.tech/article/cache-traffic-tip#:~:text=%EB%B0%9C%EC%83%9D%ED%95%A0%20%EC%9C%84%ED%97%98%EB%8F%84%20%EC%9E%88%EC%96%B4%EC%9A%94.-,%ED%95%B4%EA%B2%B0%EC%95%88%3A%20%EC%A7%80%ED%84%B0(Jitter),-%EC%BA%90%EC%8B%9C%20%EB%A7%8C%EB%A3%8C%20%EC%8B%9C%EA%B0%84%EC%9D%84)
        - 마감 시점을 분산시켜 한꺼번에 만료되는 상황을 방지한다.

**캐시 시스템 장애**

- 캐시 시스템 자체에 장애가 생기는 문제이다.
- DB로 요청을 재전송 할 수 있겠지만, 무작정 그러면 안된다.
    - 왜냐하면 이렇게 했을 때 DB로 가는 부하가 커지기 때문에, 다른 기능마저 성능이 저하되거나, 최악의 경우 다운될 수 있다.
    - 핵심 기능을 정의하여 그 기능을 제외한 경우 기능이 복구될 때까지 예외 페이지를 띄우는 것도 하나의 방법이다.

## 분산 캐시 시스템의 주요 기술

### Redis vs Memcached

| 항목 | Redis | Memcached |
| --- | --- | --- |
| 데이터 구조 | 문자열, 해시, 리스트, 셋, 정렬된 셋 등 | 문자열(key-value) |
| 영속성 | Snapshot(RDB), AOF | 없음 |
| Pub/Sub | 지원 | 미지원 |
| 사용 사례 | 실시간 랭킹, 세션 저장, 채팅 메시지 등 | 캐싱 용도 한정 |
| 쓰레드 | 단일 쓰레드(이벤트 루프 기반 비동기 I/O) | 멀티 쓰레드 |


# 참고

https://tech.kakaopay.com/post/local-caching-in-distributed-systems/#cachemanager%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%ED%86%B5%ED%95%A9-%EC%BA%90%EC%8B%9C-%EC%B2%98%EB%A6%AC

https://velog.io/@sleekydevzero86/distributed-system-data-consistency

https://mark-kim.blog/cap_pacelc/CAP_PACELC_theorem/

https://ayoung0073.tistory.com/entry/Cache-%EC%BA%90%EC%8B%B1

https://velog.io/@ekxk1234/Redis-Cluster

https://toss.tech/article/cache-traffic-tip

https://hudi.blog/concurrency-issue-causing-redis-cache-consistency-problem/
