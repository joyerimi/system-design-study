# 가상 면접 사례로 배우는 대규모 시스템 설계 기초(6장)

스터디 날짜: 2025년 7월 16일

# 키-값 저장소

- 키-값 데이터베이스라고도 불린다.
- 비 관계형 데이터베이스이다.
- 고유 식별자를 키로 가져야 한다. 즉, 키는 유일해야 한다.
- 값은 키를 통해서만 접근할 수 있다.
- 성능상의 이유로 키는 짧을수록 좋다.
    - 어째서 키가 짧은 것이 좋을까?

# 단일 키-값 저장소

- 가장 간단한 구현 방법은 key-value pair를 전부 메모리에 해시 테이블로 저장하는 것이다.

## 장점

- 빠른 속도를 보장

## 단점

- 모든 데이터를 메모리 안에 두는 것이 불가능할 수 있음

## 해결책

- 데이터 압축
- 자주 쓰이는 데이터만 메모리에 두고 나머지는 디스크에 저장

# 분산 키-값 저장소

- 앞의 해결책으로도 부족할 때 도입할 필요가 있다.
- key-value pair를 여러 서버에 분산시키는 것이다.
- 분산 시스템을 설계하기 위해서는 CAP 정리를 이해하고 있어야 한다.

## CAP 정리

- CAP 정리는 Consistency(데이터 일관성), Availability(가용성), Partition Tolerance(분할 내성) 세 가지 요구사항을 동시에 만족하는 분산 시스템을 설계하는 것은 불가능하다는 정리이다.
    - Consistency: 분산 시스템에 접속하는 모든 클라이언트는 **어떤 노드에 접속했느냐에 관계없이 언제나 같은 데이터를 보게 되어야 한다**.
    - Availability: 분산 시스템에 접속하는 클라이언트는 **일부 노드가 장애가 발생하더라도 항상 응답을 받을 수 있어야 한다**.
    - Partition Tolerance: 파티션은 두 노드 사이에 통신 장애가 발생하였음을 의미한다. **네트워크에 파티션이 생기더라도 시스템은 계속 동작하여야 한다는 것을 뜻한다.**
- CAP 세 가지를 전부 만족하는 것은 불가능하기 때문에 셋 중 두 개를 선택해야 한다.
    
    <img width="50%" alt="image" src="https://github.com/user-attachments/assets/27d611c0-bad7-4b5a-8ed1-20ee23b69606" />

    
    - 그렇다고 하지만 현실 세계에서 partition tolerance는 포기할 수 없다고 합니다. 즉, CP와 AP 중에서 선택해야 합니다.
    - 그 이유는 무엇일까요?
        
        현실에서 네트워크가 안 끊어질 것이라는 보장을 할 수 없음. 우리는 항상 네트워크의 단절에 대해서 주의해야 함.
        
        특히 분산 환경에서 노드 간 통신이 안 될 때 아예 고장나버린다면 고가용성은 불가능하고 서비스 장애와 다름이 없다고 여겨짐.
        

### CP vs AP 예시

<img width="50%" alt="image 1" src="https://github.com/user-attachments/assets/adcd4f14-0718-47ab-b36f-055fa9998240" />


이 상황에서 일관성을 선택하게 된다면,

- 세 서버 사이에 생길 수 있는 데이터 불일치 문제를 피하기 위해서 n1과 n2에 대해서 쓰기 연산을 중단시켜야 한다.
- 이는 은행권 시스템에서 주로 볼 수 있다.

가용성을 선택하게 된다면,

- 어느 한 노드는 오래된 데이터를 반환하더라도 계속 쓰기 연산과 읽기 연산을 허용해야 한다.
- 나중에 n3 노드가 복구 된다면 새로운 데이터를 n3에 전송하게 된다.

CAP의 부족함을 지적하며 등장한 PACELC. 단순히 partition 환경에서만 trade-off를 고민할 것이 아니라 멀쩡한 환경에서도 trade-off를 고민해야 한다.

<details>
  <summary>GPT ficial</summary>
    
  아래에서는 PACELC 이론의 의미와 탄생 배경, 각 문자(Trade‑off 지점)가 가리키는 바, 그리고 실제 분산 데이터베이스 설계에 어떻게 적용되는지를 차근차근 살펴보겠습니다.
    
  ---
  
  ## 1. PACELC 개요
  
  - **PACELC** 는 Daniel J. Abadi(2010)가 제안한 CAP 정리의 확장 모델
  - **CAP** 이론이 “Partition 발생 시 Availability↔Consistency”만 고려하는 한계를 보완
  - **PACELC** 는
      - **P**: Partition(네트워크 분할)
      - **A/C**: Partition 시 Availability vs Consistency 중 선택
      - **E**: Else(분할이 없을 때)
      - **L/C**: 분할 없을 때 Latency vs Consistency 중 선택
  
  > “P가 발생하면 A와 C 중 무엇을 택하고, Else(정상 상태)에는 L과 C 중 무엇을 택할 것인가”를 명시
  > 
  
  ---
  
  ## 2. 각 문자(Trade‑off) 의미
  
  | 문자 | 의미 | 설명 |
  | --- | --- | --- |
  | P (Partition) | 네트워크 분할 | 노드 간 통신이 끊기거나 지연이 심해져 서로 메시지를 주고받기 어려운 상태 |
  | A (Availability) | 가용성 | 항상 요청에 응답을 돌려주는 특성. 데이터 최신성이 보장되지 않을 수 있음 |
  | C (Consistency) | 일관성 | 모든 노드가 같은 시점의 동일한 데이터를 보장. 응답 지연이나 실패가 발생할 수 있음 |
  | E (Else) | 정상 상태 | 분할이 발생하지 않은 “평상시” 운영 환경 |
  | L (Latency) | 지연 시간 | 응답 속도, 특히 읽기/쓰기 지연을 최소화하는 특성 |
  | C (Consistency) | 일관성 | 위와 동일. 정상 상태에서도 일관성을 얼마나 중시할지 |
  
  ---
  
  ## 3. PACELC가 만들어진 배경
  
  1. **CAP 한계**
      - CAP 이론은 “Partition 발생 시”에만 트레이드오프를 논의
      - 현실 분산 시스템은 Partition 없이도 “일관성 vs 지연” 평가가 필요
  2. **실제 설계 고려 요소**
      - 대규모 시스템에서는 **지연(latency)** 최적화가 서비스 품질에 직결
      - **일관성(consistency)** 요구 수준도 워크로드마다 다름
  3. **PACELC 등장**
      - Partition 시와 정상 상태 시를 **모두** 명시적으로 다루는 모델 제안
      - 각 단계별 설계 지침을 분명히 함
  
  ---
  
  ## 4. PACELC 플로우
  
  ```
        ┌──────────┐
        │   P 발생   │─── A 선택 ── 가용성↑ / 일관성↓
        │(분할 상태)│
        └──────────┘
              │
             C 선택 ── 일관성↑ / 가용성↓
              ↓
  ┌───────────────────────┐
  │      Else 상태        │─── L 선택 ── 지연↓ / 일관성↓
  │   (정상/비분할 상태)  │
  └───────────────────────┘
              │
             C 선택 ── 일관성↑ / 지연↑
  
  ```
  
  ---
  
  ## 5. 대표 시스템의 PACELC 선택 사례
  
  | 시스템 | Partition 시 | Else(정상 시) |
  | --- | --- | --- |
  | Amazon Dynamo | A (가용성) | L (지연) |
  | Apache Cassandra | A | L |
  | HBase (Bigtable 계열) | C (일관성) | C (일관성) |
  | Azure Cosmos DB (multi‑model) | tunable: PC/PA | tunable: EC/EL |
  | MongoDB (기본) | A | C |
  - **Dynamo/Cassandra**
      - **PA/EL**: 장애에도 쓰기·읽기 응답 유지, 정상 시에는 지연 최소화 대신 최종적 일관성 선택
  - **HBase**
      - **PC/EC**: 장애 시에는 일관성(데이터 정확성) 선택, 정상 시에도 강일관성(strict consistency) 지향
  - **Cosmos DB, MongoDB**
      - 사용자가 여러 수준의 일관성 모델(strong, bounded staleness, eventual 등)을 **구성** 가능
      - 각 모드에 맞춰 P시·Else시 트레이드오프 선택
  
  ---
  
  ## 6. 설계 시 활용 포인트
  
  1. **서비스 특성 파악**
      - 지연 민감도 높은 읽기 서비스 vs 트랜잭션 일관성 필수 서비스
  2. **워크로드 프로파일링**
      - 쓰기 집중 vs 읽기 집중
  3. **일관성 모델 선택**
      - 최종적 일관성(eventual) → 낮은 지연 / 높은 가용성
      - 강일관성(strong) → 높은 지연 / 낮은 가용성
  4. **운영 환경 고려**
      - 예상 Partition 빈도
      - 리전 간 레이턴시, 장애 복구 요구 수준
  
  ---
  
  ## 7. 결론
  
  - **PACELC** 는 “분산 시스템 설계 시 두 가지 상황(P 발생 vs Else) 모두에서 어떤 특성을 희생할 것인가”를 명확히 해 줍니다.
  - 이를 통해 단순한 CAP 정리 그 이상으로, **지연(latency)–가용성–일관성** 사이의 균형점을 잡는 데 실질적인 가이드라인을 얻을 수 있습니다.
  
  더 궁금하신 예시나, 특정 데이터베이스의 PACELC 전략 비교가 필요하시면 편하게 질문해 주세요!
    
</details> 

## 시스템 컴포넌트

### 데이터 파티션

대규모 시스템의 경우 전체 데이터를 하나의 서버에서 관리하는 것은 불가능하다. 이를 해결하기 위해서는 각 데이터를 여러 개의 작은 파티션들로 분할한 다음 여러 개의 서버에 저장하는 것이다.

다만, 파티션을 나눌 때 두 가지 문제를 중요하게 따져야 한다.

- 데이터를 여러 서버에 고르게 분산할 수 있는가?
- 노드가 추가되거나 삭제될 때 데이터의 이동을 최소화할 수 있는가?

이러한 문제는 안정 해시를 사용해서 해결할 수 있다. 안정 해시의 장점은 다음과 같다.

- 규모 확장 자동화: 시스템 부하에 따라 서버가 자동으로 추가되거나 삭제되도록 할 수 있다.
- 다양성(heterogeneity): 각 서버의 용량에 맞게 가상 노드의 수를 조정할 수 있다.
    - heterogeneity의 뜻이 무엇일까? 어떤 의미에서의 다양성일까? 다양한 옵션을 가질 수 있다는 걸까?

### 데이터 다중화

파티셔닝은 **너무 많은 양의 서로 다를 수 있고 같을 수 있는** 데이터를 여러 개의 서버에 분산시킨다면, 다중화의 경우 **동일한 데이터**를 여러 개의 서버에 복제하는 것이다.

즉, 파티셔닝은 scalability에 다중화는 availability와 reliability에 더욱 집중한다고 볼 수 있다. 다중화를 통해서 여러 데이터 센터에 같은 데이터를 적재한다.

- (Availability) client는 자신에게 더 가까운 데이터 센터를 통해 빠르게 데이터를 전달 받을 수 있다.
- (Reliability) server는 동일한 데이터를 여러 데이터 센터에 나누어 저장하면서 하나의 데이터 센터에 문제가 생기더라도 다른 데이터 센터를 통해 서비스를 이어 제공할 수 있다.

consistent hash로 구현할 때 주의할 부분이 있다. 가상 노드로 인해서 연달아 존재하는 노드가 사실은 같은 서버를 가리키고 있을 수 있다. 이때 제대로 된 다중화의 효과가 드러나지 않을 수 있다.

- 선택된 노드들이 중복된 데이터 센터를 가리키지 않도록 해야 한다.

### 데이터 일관성

여러 노드에 다중화된 데이터는 적절히 동기화가 되어야 한다.

그런데 아무때나 동기화되어 있다고 판단하면 안 된다. 여러가지 문제가 생길 수 있다.

- 오래된 데이터가 최신 데이터라고 판단될 수 있다.
- 최신 데이터를 잃어버릴 수 있다.
- 등등..

이러한 문제를 해결하기 위해서는 정족수 합의(Quorum Consensus) 프로토콜을 사용할 수 있다.

정족수는 N, W, R을 통해서 결정될 수 있다.

- N: 사본 개수
- W: 쓰기 연산에 대한 정족수, 쓰기 연산이 성공한 것으로 간주되려면 적어도 W개의 서버로부터 쓰기 연산이 성공했다는 응답을 받아야 한다.
- R: 읽기 연산에 대한 정족수, 읽기 연산이 성공한 것으로 간주되려면 적어도 R개의 서버로부터 응답을 받아야 한다.

N, W, R의 값을 통해서 서비스의 특징이 정해질 수 있다.

- W의 값이 1일 때, 단 하나의 서버에서만 쓰기 완료 됐다는 응답이 오면 되기 때문에 쓰기 작업이 굉장히 빨라진다.
- R의 값이 1일 때, 단 하나의 서버에서만 응답이 오면 되기 때문에 읽기 작업이 굉장히 빠르다.

하지만 W와 R의 값이 적을 수록 일관성에 대한 보장이 줄어든다.

- W+R ≤ N: **강한 일관성**이 보장되지 않는다. 최악의 경우 겹치는 복제 서버가 없을 수 있다.
    
    <img width="50%" alt="image 2" src="https://github.com/user-attachments/assets/f22b70e0-d814-4d21-ac46-37006ee21b79" />

    
- W+R > N: **강한 일관성**이 보장된다. 적어도 하나의 복제 서버는 최신의 데이터를 가지고 있다.
    
    <img width="50%" alt="image 3" src="https://github.com/user-attachments/assets/66c8d90b-5af1-4f1f-87f1-05bb554e8ca0" />

    

**약한 일관성? 강한 일관성? 일관성 모델에 대해서**

일관성 모델은 데이터 일관성의 수준을 결정하는데, 종류가 다양하다.

- 강한 일관성: 모든 읽기 연산은 가장 최근에 갱신된 결과를 반환한다. 클라이언트는 절대로 오래된 데이터를 보지 못한다.
    - 이를 달성하기 위해서는 모든 사본에 현재 쓰기 연산의 결과가 반영될 때까지 해당 데이터에 대한 읽기/쓰기를 금지하는 것이다.
    - 모든 사본이 같은 데이터가 반영될 때까지 기다려야 하기 때문에 고가용성이 필요한 시스템에서는 부적합하다.
- 약한 일관성: 읽기 연산은 가장 최근에 갱신된 결과를 반환하지 못할 수 있다.
- 결과적 일관성(최종적 일관성): 약한 일관성의 한 형태로, 갱신 결과가 결국에는 모든 사본에 반영되는 모델이다.
    - 쓰기 연산이 병렬적으로 발생하면 시스템에 저장된 값의 일관성이 깨질 수 있다. 이 문제는 클라이언트가 해결해야 한다.
    - 클라이언트는 버전 정보를 활용해서 일관성이 깨진 데이터를 읽지 않도록 할 수 있다.

### 일관성 불일치 해소

데이터 다중화를 하면 가용성은 높아지지만 사본 간 일관성이 깨질 가능성이 높아진다. 이러한 문제를 최소화 하기 위해서 버저닝과 벡터 시계를 사용한다.

<img width="50%" alt="image 4" src="https://github.com/user-attachments/assets/7fcdaed9-8721-48ee-8f25-a2a882fa8e67" />


위의 그림을 본다면 각 서버는 각각의 db replica를 보고 있다. 이때 서로 같은 행에 다른 값을 update 한다면  conflict가 생긴다. 이때 생기는 충돌을 해결하기 위해서 **버저닝 시스템**이 필요하고, **벡터 시계는 보편적으로 사용되는 기술**이다.

```
버저닝 시스템 ⊃ 벡터 시계

버저닝 시스템
- state나 event에 고유한 version tag를 붙여서 history나 conflict를 관리하는 매커니즘이다.

벡터 시계
- 분산 시스템에서 노드(혹은 프로세스)가 자신과 다른 노드의 이벤트 개수를 배열 형태로 기록하여 partial order로 판단하게 한다.
```

**벡터 시계**

벡터 시계는 [서버, 버전]의 순서쌍을 데이터에 포함하는 것이다. 이 순서쌍은 어떤 버전이 선행인지, 후행인지, 아니면 다른 버전과 충돌이 있는지 판별하는 데 쓰인다.

- D([S1, v1], [S2, v2], [S3, v3], …, [Sn, vn])
- D는 데이터, Si는 서버 번호, vi는 버전 카운터

데이터 D를 서버 Si에 기록하면, 시스템은 아래 가운데 하나를 수행해야 한다.

- [Si, vi]가 있으면 vi를 증가시킨다.
- 없으면 [Si, 1]을 만든다.

<img width="50%" alt="image 5" src="https://github.com/user-attachments/assets/7311d015-7e07-4865-bf85-5f0d266f5632" />


- 5번에서 충돌 해소의 주체가 Sx이기 때문에 Sx의 버전이 올라가는 것이다. 만약 Sa가 충돌 해소의 주체였다면 새롭게 [Sa, 1]이 생기는 것이다.

**벡터 시계의 단점**

- 충돌 감지 및 해소 로직이 클라이언트에 들어가야 하므로, 클라이언트 구현이 복잡해진다.
- [서버: 버전]의 순서쌍의 수가 굉장히 빠르게 늘어난다. 이러한 문제를 해결하기 위해서는 threshold 이상의 길이가 되면 오래된 순서로 벡터 시계에서 제거하도록 해야 한다.
    - 하지만 이게 쉬운 것이 아닌 게, 버전 간 선후 관계가 정확하게 결정될 수 없기 때문이다.

### 장애 처리

대규모 시스템에서 장애는 흔하게 벌어진다. 그렇기 때문에 회피만 할 것이 아니라 적절히 처리할 수 있어야 한다.

장애를 처리하기 위해서는

- 장애 감지
- 장애 해소

에 대해서 알아보아야 한다.

### 장애 감지

분산 시스템에서 장애 감지에 대해서 가장 쉽게 아는 방법은 모든 노드 사이에 멀티캐스팅 채널을 구축하는 것이다.

- 하지만 서버가 많아지게 된다면 N(N-1)/2이기 때문에 약 N^2개의 연결이 생긴다. 이는 비효율적이다. Gossip protocol이나 분산형 장애 감지 솔루션이 훨씬 효율적이다.

**가십 프로토콜이란?**

가십 프로토콜 또한 결국에 분산 환경에서 메시지를 전달하는 방식이다. 하지만 모든 노드들에 정보를 보내는 것이 아니라, 무작위 몇 개의 노드들에만 정보를 보내고, 해당 노드들이 또 다른 노드들에 정보를 보내는 방식이다.

- 각 노드는 멤버십 목록을 유지한다. 멤버십 목록 = (id, 박동 카운터) / 여기에 업데이트 된 시간을 함께 관리한다.
- 각 노드는 주기적으로 자신의 박동 카운터를 증가시킨다.
- 각 노드는 무작위로 선정된 노드들에게 주기적으로 자기 박동 카운터 목록을 보낸다.
- 박동 카운터 목록을 받은 노드는 멤버십 목록을 최신 값으로 갱신한다.
    - 최신값이라는 게 뭐지? 중간중간 다른 값들 중에서 가장 큰 값이 최신 값인가?
- 어떤 멤버의 박동 카운터 값이 지정된 시간 동안 갱신되지 않으면 해당 멤버는 장애 상태인 것으로 간주한다.

<img width="50%" alt="image 6" src="https://github.com/user-attachments/assets/1f54213b-d18d-4de5-a4f2-3eb38aa6d2d0" />


- S0는 S2가 오랫동안 heartbeat counter를 올리지 않은 것을 확인한다.
- S0은 S1, S3에게 이를 전달한다.
- S3는 S4, S5에 다시 전달한다.

그런데 이렇게 하면 멀티 캐스팅보다 장애 상태에 대한 전파의 속도가 느려지지 않을까?

- 결론부터 말하자면 아니다.
    - log scale로 증가하기 때문에 $O(logN)$의 시간복잡도를 가진다.
- <details>
  <summary>자세한 증명..? by GPT</summary>
    가십 프로토콜이 “완벽하게 효율적”으로만 동작하는 건 아닙니다. 즉, 이미 알고 있는 노드에 중복 전파(duplicate gossip)를 하는 경우도 분명히 생기지만, **전체 전파 시간 복잡도**가 여전히 **O(log N)** 으로 유지되는 이유를 좀 더 살펴보겠습니다.
    
    ---
    
    ## 1. 중복 전파가 있어도 지수적 성장 유지
    
    1. **유효 전파율(effective fan-out)**
        - 한 라운드에 fan-out $f$로 보낼 때,
            - $I(t)$가 이미 알고 있는 노드 수
            - $N$이 전체 노드 수
            - “새로운” 노드에게 도달할 확률 ≈ $\displaystyle \frac{N - I(t)}{N}$
        - 그래서 **기대 신규 전파 수**는
            
            $ΔI(t)
              \;=\; I(t)\times f \times \frac{N - I(t)}{N}$
            
        - $\displaystyle \frac{N - I(t)}{N}$ 이 1에 가까울 땐(초기 단계)
            
            $\Delta I(t) \approx I(t)\times f$ → 지수 성장
            
        - 결국 $I(t)$가 커질수록(말단에 가까워질수록) 중복이 늘어나 성장 속도는 느려지지만, **초기·중기 단계**에서의 “복제 계수(reproduction number)”가 1보다 훨씬 크기 때문에 전체 분포 지연이 여전히 $\Theta(\log N)$ 을 보장합니다.
    
    ---
    
    ## 2. 로지스틱 성장 모델
    
    - 위 식은 사실 **로지스틱 곡선**과 유사하게 동작합니다.
    - 연속 모델로 보면 미분방정식
        
        $\frac{dI}{dt} = f\;I\;\bigl(1 - \tfrac{I}{N}\bigr)$
        
        의 해(해석해 보면) 대략
        
        $\displaystyle I(t)=\frac{N}{1 + \bigl(\frac{N-1}{1}\bigr)e^{-f\,t}}$
        
    - 이 식에서 “$I(t)$가 $N/2$가 되는 시점”은
        
        $\displaystyle t = \frac{1}{f}\ln(N-1)\approx O(\ln N)$ 이고,
        
        “거의 모든 노드(예: $0.99N$)”가 되는 시점도 $O(\ln N)$ 안쪽입니다.
        
    
    ---
    
    ## 3. Push-Pull 혼합
    
    - **Push-only**(순수 전파) 만 쓰면
        - 초기엔 폭발적이지만, $I(t)$가 커질수록 중복 전파 비율이 높아져 “말단 전파 지연(long tail)”이 늘어납니다.
    - **Pull-only**(요청 방식) 만 쓰면
        - 말단은 잡아내지만 초기 확산이 느림.
    - **Push-Pull** 혼합 시
        - 초반엔 Push로 빠르게 퍼뜨리고, 중후반엔 Pull로 남은 소수 노드를 효율적으로 흡수(“누락 리커버리”)
        - 전체 지연이 더욱 일정하게 $O(\ln N)$ 레벨로 유지됩니다.
    
    ---
    
    ## 4. 요약
    
    | 구분 | 장점 | 단점 | 전파 라운드 복잡도 |
    | --- | --- | --- | --- |
    | Push-only | 초기 확산 매우 빠름 | 말단 중복으로 느린 tail 발생 | $O(\ln N)$ (초기) |
    | Pull-only | 누락 노드 확실히 검출 가능 | 전체 확산 속도 느림 | $O(N)$ 근사 |
    | Push-Pull | 초기·말단 모두 균형 잡힌 확산 | 구현 복잡도 약간 증가 | $O(\ln N)$ |
    - **중복 전파**가 완전히 없어지진 않지만,
        1. “지수적 복제 계수”
        2. “Push-Pull 보완”
            
            두 가지 메커니즘 덕분에
            
            → **중복이 일부 있더라도**
            
            → **대규모 분산 시스템에서 $\mathbf{O(\log N)}$ 전파 시간**이 유지됩니다.
            
    
    ---
    
    > 결론:
    > 
    > - “이미 알고 있는 노드에 보내는 중복 전파”가 있더라도
    > - 평균적으로는 충분한 재생산 계수(reproduction number)로 인해
    > - **$O(\log N)$** 라운드 안에 거의 모든 노드가 상태를 알게 됩니다.
    > - 그리고 실제 구현 시에는 **Push-Pull**이나 **간접 Ping_req** 같은 기법으로 tail 지연을 추가로 줄입니다.
    
    이렇게 보면, “꼭 모르는 노드에만 전파”하지 않아도 **복제 계수**와 **혼합 정책**으로 충분히 빠르게 전파가 이루어진다는 걸 직관적으로 이해할 수 있을 거예요.
  
</details>
        
        
- 나중에는 log scale로 증가하지 않을 수 있지만, 그때가 되면 절반 이상이 업데이트 돼있기 때문에 pull 방식을 통해서 상수 시간 안에 해결할 수 있다.

### 장애 해소

일시적 장애를 처리하는 방법

- 엄격한 정족수 접근법에서는 읽기와 쓰기 연산을 금지해야 한다.
- 느슨한 정족수 접근법에서는 쓰기와 읽기를 허용하여 가용성을 높이는 대신에 정족수 요구사항을 만족시키는 R와 W를 해시 링에서 고른다. 이때 장애 노드는 R과 W를 선택하는 데에서 제외된다.
    - 네트워크나 서버 문제로 인해서 장애 상태인 서버로 가는 요청은 다른 서버가 잠시 맡아서 처리한다. 그 사이에 생긴 변경사항은 해당 서버가 복구되었을 때 일괄 반영하여 데이터 일관성을 보존한다.(최종적 일관성)
    - 일괄 반영을 위해서 변경 사항과 함께 hint를 적어놓는데, 이를 hinted handoff라고 한다.

영구적 장애를 처리하는 방법

- anti-entropy 프로토콜을 구현하여 사본들을 동기화할 수 있다.
    - anti-entropy의 종류 중 하나가 Merkle tree이다.
    - 머클트리는 리프 노드부터 해서 가장 가까운 두 개의 노드들의 해시 값을 더하는 방식을 반복하여 하나의 머클 루트를 찾는 방법이다.
    - 이렇게 하나의 머클 트리를 완성했을 때 두 서버의 차이를 비교하는 것에는 각 노드에 저장된 해시 값을 비교하는 것만 이루어지면 된다.
        
        <img width="50%" alt="image 7" src="https://github.com/user-attachments/assets/27f56df5-ea6c-4d03-8a01-4942650398d3" />

        
    - 루트의 값이 같은 경우에는 두 서버가 아예 같은 사본을 가지고 있다고 판단할 수 있다.
    - 하지만 루트의 값이 다른 경우에는 밑으로 내려가면서 다른 값을 찾는 과정을 반복하여 최종적으로 다른 데이터를 갖는 버킷을 찾을 수 있다.
    - 머클 트리를 사용하게 되면 어느 부분에서 차이가 생기는지 알 수 있기 때문에 실제로 차이가 있는 부분에 비례하여 동기화하면 된다. 전체 데이터의 크기와는 상관이 없다.

영구적 장애를 처리한다는 것의 의미는 무엇일까?

- 멀쩡한 노드들끼리의 사본을 교환한다는 뜻인가?
    - 하나의 노드가 장애가 되었을 때 사본을 교환해야 하는 이유는?
- 새로운 노드를 들이기 위해서 사본을 교환한다는 뜻인가?
- 근데 목적이 무엇이 되든 간에 사본을 교환해서 최신의 버전으로 유지한다는 게 포인트인듯

anti-entropy protocol의 종류?

- push mechanism
- pull mechanism
- push-pull mechanism
- merkle tree
- gossip protocol
- hinted handoff (GPT는 얘가 anti-entropy protocol은 아니라고 함)
    - <details>
      <summary>GPT ficial</summary>
        아니요, **Hinted Handoff**는 **Anti‑entropy 프로토콜**과는 다른 목적과 동작 방식을 갖는 메커니즘입니다.
        
        ---
        
        ## 1. Hinted Handoff 개요
        
        - **목적**
            - 일시적으로 다운된(replica) 노드가 있을 때도 **쓰기 가용성**을 보장하기 위해
        - **동작 방식**
            1. 클라이언트가 쓰기 요청을 중재자(coordinator)에게 보냄
            2. 특정 복제본 노드(예: n2)가 다운된 상태라면, coordinator는 그 노드 대신 **힌트(hint)** 를 갖고 있음
            3. 힌트는 “n2가 복구되면 이 쓰기(키·값)를 대신 전송하라”는 예약 정보
            4. 다운된 노드가 복구되면, coordinator 또는 다른 노드가 힌트를 읽어 n2로 **재전파(replay)**
        
        ---
        
        ## 2. Anti‑entropy 프로토콜과의 차이
        
        | 구분 | Hinted Handoff | Anti‑entropy (예: Gossip) |
        | --- | --- | --- |
        | 주요 목적 | 일시 장애 시에도 **즉시 쓰기 성공** 보장 | 장애 복구 후에도 **최종 일관성** 유지 |
        | 동기화 대상 | 다운된 특정 노드 하나에 대한 “예약된” 변경분 | 모든 살아 있는(replica) 노드 간 **주기적 상호 동기화** |
        | 발생 시점 | 쓰기 요청 시 장애 감지 → 힌트 저장 | 장애 복구 후 또는 주기적으로(정기적으로) |
        | 전파 방식 | 힌트 저장소 → 단일 노드(복구된 노드)에게 재전송 | 랜덤 피어 간 Push/Pull(Gossip), Merkle Tree 비교 등 |
        | 장점 | 짧은 장애 구간에도 높은 가용성 제공 | 임시·영구 장애 후에도 클러스터 전체 일관성 보장 |
        
        ---
        
        ## 3. 요약
        
        1. **Hinted Handoff**
            - “장애 난 복제본이 복구될 때까지 대신 써 두는” **쓰기 예약** 메커니즘
        2. **Anti‑entropy**
            - “살아 있는 모든 복제본끼리 주기적으로 상태를 비교·교환”하는 **일관성 보강** 메커니즘
        
        → 두 기법은 **상호 보완적**으로 사용되며, hinted handoff가 쓰기 가용성을, anti‑entropy가 최종 일관성을 책임집니다.
        
    </details>   
        

### 시스템 아키텍처 다이어그램

<img width="50%" alt="image 8" src="https://github.com/user-attachments/assets/4eb8c5b9-a6d3-4425-9a16-54623a4ec05c" />


- 클라이언트는 key-value 저장소가 제공하는 두 가지 단순한 API와 통신한다.
- 중재자는 클라이언트에게 키-값 저장소에 대한 proxy 역할을 하는 노드이다.
- 노드는 consistent hash의 hash ring 위에 분포한다.
- 노드를 자동으로 추가 또는 삭제할 수 있도록, 시스템은 완전히 분산(decentralized)된다.
- 데이터는 여러 노드에 다중화된다.
- 모든 노드가 같은 책임을 가지므로 SPOF는 존재하지 않는다.

중재자에 장애가 생기면 어떻게 하나?

- 결론부터 말하자면 문제가 없다.
- **중재자는 고정된 존재가 아니다.** 클라이언트는 미리 알고 있는 node들의 list에 라운드 로빈, 랜덤, 가중치 등등의 방법으로 돌아가며 요청을 보내면 된다.
    - 적어도 한 번의 요청과 응답이 오고 가면, 클라이언트는 전체 노드의 list를 알 수 있다.
- 만약 처음 알고 있는 모든 node 들에 장애가 생긴다면 어떡하나?
    - **초기 모든 Seed 장애** 시에는 클러스터 토폴로지 획득 불가 → **재시도 후 예외 발생** → 운영자 개입
    - 이를 방지하려면 **Seed 수, 분산 배치, DNS/SRV, 서비스 레지스트리, LB** 등을 복합 활용
    - 모니터링과 자동 프로비저닝으로 Seed 가용성을 유지하면 초기 부트스트랩 실패를 효과적으로 줄일 수 있음

### 쓰기 경로

<img width="50%" alt="image 9" src="https://github.com/user-attachments/assets/0e575f39-9998-4492-8e39-302b754748d6" />


1. 쓰기 요청이 커밋 로그 파일에 기록된다.
2. 데이터가 메모리 캐시에 기록된다.
3. 메모리 캐시가 가득차거나 사전에 정의된 어떤 임계치에 도달하면 데이터는 디스크에 있는 SSTable(Sorted String table)에 기록된다.

**key-value store에서 SSTable을 이용하는 이유가 뭘까?**

| 번호 | 이유 | 설명 |
| --- | --- | --- |
| 1 | 순차 쓰기 최적화 | 디스크에 랜덤 쓰기 대신 **오직 순차 쓰기**만 수행 → 디스크 I/O 비용 절감 |
| 2 | 불변 파일 | 한 번 생성된 SSTable은 수정하지 않으므로 동시성 제어(lock) 단순화 |
| 3 | 효율적 병합(compaction) | 정렬된 SSTable끼리 **병합 정렬(merge)** 하여 오래된 레코드 삭제·압축 |
| 4 | 빠른 조회 | 인덱스+Bloom filter로 존재 여부 검사 후, 최소한의 블록만 디스크에서 읽음 |
| 5 | 범위 쿼리 지원 | 키가 정렬되어 있어 연속적인 레코드 스캔이 **디스크 시크 감소**로 고속 수행 |
| 6 | Crash Recovery | 불변 파일 + Write‑Ahead Log(WAL) 조합으로, 장애 복구가 간단 |

**SSTable이 순차 쓰기에 최적화 된 이유는 뭘까?**

- 메모리에서 먼저 정렬(MemTable)
    - 모든 쓰기 요청은 우선 메모리(MemTable)에 `키 오름차순` 상태로 삽입
    - MemTable은 보통 **균형 트리(Red‑Black Tree)** 혹은 **Skip List** 로 구현
- Flush 시 한 번에 덤프(Dump)
    
    ```
    text
    복사편집
    if (MemTable.size() ≥ threshold) {
      // 1) 디스크에 새로운 SSTable 파일 생성(open for append)
      // 2) MemTable의 데이터를 키 순서대로 순회(iterator)
      // 3) iterator가 가리키는 순서대로 write(append) → 순차 쓰기
      // 4) 파일 close
      MemTable.clear()
    }
    ```
    
    - **정렬된 순서(key1, key2, …)** 로 한 덩어리씩 연속 기록
    - 디스크 입장에선 “헤드를 맨 앞에 놓고, 블록을 계속 써 내려간다”와 동일
- Write‑Ahead Log(WAL) 역시 순차 Append
    - 장애 복구를 위한 WAL도 **항상 파일 끝에 붙이는(Append‑Only)** 방식
    - SSTable flush 전후의 순서를 보장하면서도 랜덤 I/O 없이 기록
- 컴팩션(Compaction) 과정도 순차 병합
    - 여러 SSTable을 병합할 때도, 각 파일을 순서대로 스캔하면서
    - 새로운 SSTable 파일에 순차적으로 내보냄 → 다시 순차 쓰기

**메모리에서 정렬된 상태로 disk에 쓴다고 했는데, 그러면 여러번 나눠서 disk에 써야하는 경우에는 어떻게 정렬을 유지하지?**

메모리로는 너무 커서 한꺼번에 정렬·플러시할 수 없는 규모일 때는, 외부 정렬 기법을 씁니다.

1. 부분 정렬 & 스플릿
    - 메모리가 허용하는 크기만큼(예: 64 MB) 데이터 덩어리(chunk)를 뽑아
    - 메모리 내에서 정렬 → **sorted run** 파일로 디스크에 순차 쓰기
2. 여러 개의 Sorted Run
    - 이렇게 `run1, run2, … runM` 만큼 개별 SSTable 조각(또는 임시 파일)이 생성됨
    - 각 조각은 자체적으로 **키 오름차순**을 유지하며 순차 기록
3. Merge 단계 (초기 컴팩션 혹은 최종 병합)
    - `run1⋈run2⋈…` 처럼 **K-way merge** 알고리즘 수행
    - 새 SSTable 파일을 만들 때, 병합된 결과를 역시 순차적으로 **append**
    - ⇒ 최종 SSTable도 전체 키 정렬이 유지되며, 순차 쓰기

```
text
복사편집
[메모리 정렬]      [디스크 쓰기]         [외부 정렬 병합]      [최종 순차 쓰기]
chunk A → sort → runA   ─▶ 파일(runA)
chunk B → sort → runB   ─▶ 파일(runB)
…                          …
merge(runA,runB,…) → SSTable ─▶ 순차 기록
```

### 읽기 경로

<img width="50%" alt="image 10" src="https://github.com/user-attachments/assets/08eab93b-3c08-437c-bb89-cf5c0d19c86c" />


1. 메모리에 데이터가 있는지 검사한다. 있으면 바로 반환하고, 없으면 2로 넘어간다.
2. 블룸 필터를 검사한다. → 블룸 필터는 false negative는 나오지 않는다. 즉, 있는데 없다고 하지 않는다. 블룸 필터에서 없다고 한다면 SSTable들에도 반드시 없다.
3. 블룸 필터를 통해 어떤 SSTable에 키가 보관되어 있는지 알아낸다.
4. SSTable에서 데이터를 가져온다.
5. 해당 데이터를 클라이언트에게 반환한다.

# 요약 : 키-값 저장소가 가져야 하는 기능과 구현에 사용되는 기술

<img width="50%" alt="image 11" src="https://github.com/user-attachments/assets/b16ef7ee-2eba-4f6f-9b42-4d78f1caa0ff" />


# 참고

https://highscalability.com/gossip-protocol-explained/?utm_source=chatgpt.com

https://www.designgurus.io/answers/detail/what-is-a-gossip-protocol-in-distributed-systems-and-how-is-it-used-for-data-or-state-dissemination?utm_source=chatgpt.com

https://www.geeksforgeeks.org/system-design/anti-entropy-in-distributed-systems/
