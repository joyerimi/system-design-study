# 키 - 값 저장소 설계
키-값 저장소는 키-값 데이터베이스라고도 불리는 비 관계형 데이터베이스입니다.
이 저장소에 저장되는 값은 고유 식별자를 키로 가져야 합니다.
키와 값의 이런 관계를 "키-값" 쌍(pair)라고 지칭합니다.

키-값 쌍에서 키는 유일해야 하며 키에 매핑된 값은 키를 통해서만 접근할 수 있습니다.
키는 일반 텍스트일 수도 있고 해시 값일 수도 있습니다. 성능상의 이유로 키는 짧을수록 좋습니다.

- 키의 예시
  - 일반 텍스트 키 : "last_logged_in_at"
  - 해시 키 : 253DDEC4

> 키는 왜 짧을수록 좋은가? : 키 비교가 빠르다. 메모리 효율이 좋다. 한 번에 많은 데이터를 캐싱할 수 있다.
> 해시 함수로 키를 만들 때 계산이 빠르다. 하지만 너무 짧으면 충돌 가능성이 높아져 적절한 길이가 필요하다.

키-값 쌍에서 값은 문자열, 리스트, 객체 등 무엇이 오든지 크게 상관하지 않습니다.
대표적으로 아마존 DynamoDB, memcached, Redis가 있습니다.  
우리는 이번 장을 통해 다음 연산을 지원하는 키-값 저장소를 설계해 볼 것입니다.

- put(key, value) : 키-값 쌍을 저장소에 저장한다.
- get(key) : 인자로 주어진 키에 매달린 값을 꺼낸다.

## 문제 이해 및 설계 범위 확정

완벽한 설계란 없습니다. 문제 상황에 따라 읽기 / 쓰기 / 메모리 사용량 사이에 균형을 찾고,
데이터의 일관성 / 가용성 사이에 타협적 결정을 내린 설계를 만든다면 괜찮을 것입니다.
이번 장에서는 아래의 특성을 가지는 키-값 저장소를 설계해 볼 것입니다.

- 키-값 쌍의 크기는 10KB 이하이다.
- 큰 데이터를 저장할 수 있어야 한다.
- 높은 가용성을 제공해야 한다. 장애가 있더라도 빠른 응답을 해야한다.
- 높은 규모 확장성을 제공해야 한다. 트래픽 양에 따라 자동적인 서버 증설/삭제가 이루어져야 한다.
- 데이터 일관성 수준은 조정이 가능해야 한다.
- 응답 지연시간이 짧아야 한다.

## 단일 서버 키-값 저장소
한 대 서버만 사용하는 키-값 저장소를 설계하는 것은 쉽습니다.
가장 직관적인 방법은 해시 테이블에 키-값 쌍 전부를 저장하는 것입니다.
빠른 속도를 보장하긴 하지만 모든 데이터를 메모리에 두는 것이 불가능한 경우도 있다는 단점이 있습니다. 문제를 해결하기 위한 방법은 다음과 같습니다.

- 데이터 압축(compression)
- 자주 쓰는 데이터만 메모리에 두고 나머지는 디스크에 저장

하지만 서버 한 대의 한계는 금방 찾아오게 됩니다. 많은 데이터를 저장하기 위해선 **분산**이 필요합니다.

## 분산 키-값 저장소
분산 키-값 저장소는 분산 해시 테이블이라고도 불립니다. 키-값 쌍을 여러 서버에 분산시키는 탓입니다.
분산 시스템을 설계할 때는 CAP 정리를 이해하고 있어야 합니다.

### CAP 정리
**데이터 일관성(Consistency)**, **가용성(availability)**, **파티션 감내(Partition tolerance)** 라는 3가지 요구사항을 동시에
만족하는 분산 시스템을 설계하는 것은 불가능하다는 정리입니다.

- 데이터 일관성 : 분산 시스템에 접속하는 모든 클라이언트는 어떤 노드에 접속했느냐에 관계없이 언제나 같은 데이터를 봐야 한다.
- 가용성 : 분산 시스템에 접속하는 클라이언트는 일부 노드에 장애가 발생하더라도 항상 응답을 받을 수 있어야 한다.
- 파티션 감내 : 파티션은 두 노드 사이에 통신 장애가 발생하였음을 의미한다. 네트워크에 파티션이 생기더라도 시스템은 계속 동작해야 한다.

CAP 정리는 2가지를 충족하면 나머지 1가지를 희생되어야 하는 것을 의미합니다.

![Image](https://github.com/user-attachments/assets/0697f00f-9a8a-425c-b8dd-e2e6b4cee8d5)

시스템은 지원하는 요구사항에 따라 CP 시스템, AP 시스템, CA 시스템이라고 불립니다.
다만 통상 네트워크 장애는 피할 수 없는 일로 여겨지므로, 분산 시스템은 반드시 파티션 감내를 지원해야 합니다.
그러므로 CA 시스템은 존재 하지 않습니다.

### 구체적 사례
분산 시스템에서 데이터는 보통 여러 노드에 복제되어 보관됩니다. 세 대의 복제(replica) 노드 n1, n2, n3에 데이터를 복제하여
보관하는 상황을 가정해보겠습니다.

#### 이상적 사례

![Image](https://github.com/user-attachments/assets/1d1bcc69-ff32-42c3-a116-6dbe5c844195)

이상적 환경이라면 네트워크가 파티션되는 상황을 절대 일어나지 않으므로 n1에 데이터가 기록되면 자동적으로 n2와 n3에 복제됩니다.
데이터 일관성과 가용성도 만족합니다.


#### 실세계의 분산 시스템

![Image](https://github.com/user-attachments/assets/2eeb25eb-2a7b-442e-8ca2-b6b9e3eef923)

분산 시스템은 파티션 문제를 피할 수 없습니다. 파티션 문제가 발생하면 일관성과 가용성 사이에서 하나를 선택해야 합니다.
그림은 n3에 장애가 생겨 나머지 노드와 통신할 수 없는 상황을 나타냅니다.
만약 n3에 기록이 되었다면 n1과 n2데이터가 전달되지 않아 오래된 사본을 가진 채로 있게 됩니다.

- 일관성을 선택하는 경우
  - 세 서버 사이에 생길 수 있는 데이터 불일치 문제를 피하기 위해 n1과 n2에 대해 쓰기 연산을 중단시킵니다.
    보통 은행권 시스템은 데이터 일관성을 견고하게 지키려 합니다. 네트워크 파티션때문에 문제가 발생한 경우
    상황이 해결될 때 까지 오류를 반환합니다.
- 가용성을 선택하는 경우
  - 오래된 데이터를 반환할 위험이 있더라도, 계속 읽기 연산을 허용합니다. n1과 n2또한 쓰기 연산이 계속될 것이고
    파티션 문제가 해결된 후 데이터를 n3에 전송할 것입니다.

따라서 일관성과 가용성 중 어떤 것을 선택할 지 면접관과 상의하고 결정하도록 합니다.

### 시스템 컴포넌트
다음은 키-값 저장소 구현에 사용될 핵심 컴포넌트 및 기술입니다. 
- 데이터 파티션
- 데이터 다중화(replication)
- 일관성(consistency)
- 일관성 불일치 해소(inconsistency resolution)
- 장애 처리
- 시스템 아키텍처 다이어그램
- 쓰기 경로(write path)
- 읽기 경로(read path)

다이나모, 카산드라, 빅테이블의 사례를 참고하여 어떤 컴포넌트인지 살펴봅니다.

#### 데이터 파티션
대규모 애플리케이션의 경우 전체 데이터를 한 대 서버에 모두 때려넣는 것은 불가능합니다.

> 잔지바는 뭐임 그럼?  
> 대규모 애플리케이션의 경우 전체 데이터를 한 대 서버에 모두 넣는 것이 불가능하다고 하여 생각났다.  
> [누구나 알아두면 도움이 될 인가 시스템 : Google의 Zanzibar와 ReBAC](https://limm-jk.tistory.com/90)  
> [코딩애플 잔지바](https://www.youtube.com/watch?v=eyDSR_0WG4I)  
> [Google Research 논문 / 저도 Abstract만 보고 안읽었음](https://research.google/pubs/zanzibar-googles-consistent-global-authorization-system/)  
> 접근 권한을 relation tuple이란 개념을 사용해 표현하여, Google 내의 서비스끼리의 접근권한을 빠르게 조회할 수 있게 한 ReBAC 기반 저장소이다.
> 잔지바의 경우 구글의 서비스 내 모든 ACL(Access Control List)를 하나의 저장소에 저장하여 인가 여부만 저장한다.
> 여기에도 수십억 개의 객체와 권한 관계가 들어가있을텐데 어떻게 처리하는 것인지 궁금했다.  
> 물론 빠른 접근을 위해 데이터베이스 센터는 여러 국가에 다중화 해놨지만, 권한에 대한 것은 여기서만 처리한다고 하니 알고 싶어졌다.


가장 단순한 해결책은 데이터를 작은 파티션으로 분할한 다음 여러 서버에 저장하는 것입니다.
이 때 중요하게 생각할 두 가지 문제가 있습니다.
- 데이터를 여러 서버에 고르게 분산할 수 있는가?
- 노드가 추가되거나 삭제될 때 이동을 최소화할 수 있는가?

5장에서 살펴봤던 안정 해시를 이용하면 구현이 가능하니 장점만 간단히 짚고 넘어가겠습니다.
- 규모 확장 자동화가 가능하다.
- 다양성 : 각 서버의 용량에 맞게 가상노드의 수를 조정할 수 있다.

#### 데이터 다중화
높은 가용성과 안정성을 확보하기 위해서는 데이터를 N개 서버에 비동기적으로 다중화할 필요가 있습니다.
N은 튜닝 가능한 값입니다. N개 서버를 선정하는 방법은 다음과 같습니다.
- 어떤 키를 해시 링 위에 배치한다.
- 그 지점으로부터 시계 방향으로 링을 순회하면서 만나는 첫 N개 서버에 데이터 사본을 보관한다.

가상 노드를 사용한다면 위와 같이 선택한 N개의 노드가 대응될 실제 물리 서버의 개수가 N보다 작아질 수 있습니다.
이 문제를 피하려면 노드를 선택할 때 같은 물리 서버를 중복 선택하지 않도록 해야 합니다.  
같은 데이터 센터에 속한 노드는 정전, 네트워크 이슈, 자연재해 등 문제를 동시에 겪을 가능성이 있습니다.
따라서 안정성을 담보하기 위해 데이터의 사본은 다른 센터의 서버에 보관하고, 센터들은 고속 네트워크로 연결합니다.

#### 데이터 일관성
여러 노드에 다중화된 데이터는 적절히 동기화가 되어야 합니다.
정족수 합의 프로토콜을 사용하면 읽기/쓰기 연산 모두에 일관성을 보장할 수 있습니다.

> 정족수 합의 프로토콜(Quorum Consensus) : 분산 시스템에서 데이터 일관성을 유지하기 위한 합의 프로토콜입니다.
> 여러 노드에 데이터가 복제되어 있을 때 읽기/쓰기 요청을 특정 수 이상의 노드로 제한함으로써 충돌없이 정합성을 유지합니다.

관계된 정의부터 살펴보겠습니다.
- N : 사본 개수
- W : 쓰기 연산에 대한 정족수. 쓰기 연산이 성공한 것으로 간주되려면 적어도 W개의 서버로부터 쓰기 연산이 성공했다는 응답 필요
- R : 읽기 연산에 대한 정족수. 읽기 연산이 성공한 것으로 간주되려면 적어도 R개의 서버로부터 응답 필요

N이 3인 경우에 대한 예제의 상황은 다음과 같습니다.

![Image](https://github.com/user-attachments/assets/64717fa5-0c4c-4baf-94c1-e595710613fb)

W = 1인 경우는 한 대에 서버에만 기록된다는 뜻이 아닙니다. 중재자가 최소 한 대의 서버로부터 쓰기 성공 응답을 받았다는 의미입니다.
따라서 W의 수가 충족되면 나머지 노드로부터의 응답은 기다릴 필요가 없습니다.  
W, R, N의 값을 정하는 것은 응답 지연과 데이터 일관성 사이의 타협점(trade-off)을 찾는 과정입니다.
W나 R의 값이 크다면 중재자는 다수의 응답이 가장 느린 서버의 응답이 올 때까지 기다려야 하고
W나 R의 값이 작다면 일관성이 깨져있을 확률이 비교적 높을 것입니다.

W + R > N인 경우 강한 일관성이 보장됩니다. 일관성을 보증할 최신 데이터를 가진 노드가 최소 하나는 겹칠 것이기 때문입니다.
다음은 W, R, N 값을 결정할 때 도움이 되는 가이드입니다.

- R = 1, W = N : 빠른 읽기 연산에 최적화된 시스템
- W = 1, R = N : 빠른 쓰기 연산에 최적화된 시스템
- W + R > N : 강한 일관성 보장(보통 N = 3, W = R = 2)
- W + R <= N : 강한 일관성이 보장되지 않음

요구되는 일관성 수준에 따라 W, R, N의 값을 조정하면 됩니다.

#### 일관성 모델
일관성 모델은 데이터 일관성 수준을 결정합니다. 종류는 다음과 같습니다.
- 강한 일관성(strong consistency) : 모든 읽기 연산은 가장 최근에 갱신된 결과를 반환한다.
  클라이언트는 절대 낡은(out-of-date) 데이터를 보지 못한다.
- 약한 일관성(weak consistency) : 읽기 연산은 가장 최근에 갱신된 결과를 반환하지 못할 수 있다.
- 결과적 일관성(eventual consistency) : 약한 일관성의 한 형태로, 갱신 결과가 결국에는 모든 사본에 반영되는 모델이다.

강한 일관성을 달성하는 일반적인 방법은 모든 사본에 현재 쓰기 연산의 결과가 반영될 때까지 해당 데이터에 대한 읽기/쓰기를 금지하는 것입니다.
하지만 이 방법은 고가용성 시스템에는 적합하지 않습니다.
새로운 요청의 처리가 중단되기 때문입니다.  
다이나모, 카산드라 같은 저장소는 결과적 일관성 모델을 선택하므로, 여기서도 이에 맞게 키-값 저장소를 구현합니다.
결과적 일관성 모델을 선택한 경우 쓰기 연산이 병렬적으로 발생 시 시스템에 저장된 값의 일관성이 깨질 수 있는데,
이 문제는 클라이언트가 해결해야 합니다.

---

**데이터 버저닝**
**버저닝**과 **벡터 시계**는 데이터 다중화 시 일관성이 깨지는 문제를 해결하기 위해 등장했습니다.
버저닝은 데이터를 변경할 때마다 해당 데이터의 새로운 버전을 만드는 것을 의미합니다.
각 버전의 데이터는 변경 불가능해야 합니다.

![Image](https://github.com/user-attachments/assets/b877ff6a-88f3-4510-ad6a-9a9afe5e6255)

서버1에서 n1으로 쓴 것을 v1, 서버2에서 n2로 쓴 것을 v2라 하고, 동시에 쓰기 연산을 하는 경우를 생각해봅시다.
원래 값은 변경이 끝난 옛날 값이라 무시할 수 있지만, 충돌이 발생한 v1과 v2 중 무엇이 우선되어야 하는지 모릅니다.
벡터 시계는 이런 문제를 푸는데 사용되는 기술입니다.  
벡터 시계는 [서버, 버전]의 순서쌍을 데이터에 매단 것입니다. 어떤 데이터가 선행 버전인지, 다른 버전이 충돌이 있는지 판별하는 데 사용합니다.
사용법은 다음과 같습니다.
- D([S1, v1], [S2, v2], ...) 같은 방법으로 표현한다고 가정한다.(D는 데이터, S는 서버, v는 버전 카운터)
- 만일 데이터 D를 서버 Si에 기록할 때 [Si, vi]가 있다면 vi를 증가시킨다.
- 그렇지 않다면, 서버 Si에서 데이터 D를 처음 처리한다면 새 항목 [Si, 1]을 만든다.

![Image](https://github.com/user-attachments/assets/06f342ec-b331-4024-bb9a-1d8653e70dc6)

1. 클라이언트가 D1을 시스템에 기록한다.
2. 클라이언트가 D1을 읽고 D2로 업데이트하여 기록한다. 똑같은 서버 Sx가 쓰기 연산을 처리했으므로 [Sx, 1]에서 [Sx, 2]로 변경한다.
3. 다른 클라이언트가 D2를 읽어 D3로 업데이트하여 기록한다. Sy가 처리한다고 가정한다.
4. 또 다른 클라이언트가 D2를 읽어 D4로 업데이트하여 기록한다. Sz가 처리한다고 가정한다.
5. 어떤 클라이언트가 D3와 D4를 읽으면 데이터 간 충돌이 있다는 것을 알게 된다.
  충돌을 해결한 서버를 Sx라고 가정한다.

벡터 시계를 보고 vi의 값이 같거나 큰지만 살펴보면 이전 버전인지 확인이 가능합니다.
충돌을 확인하기 위해서는 X 벡터 시계의 서버와 Y 벡터 시계의 서버를 비교했을 때 한 쪽의 버전 카운터가 모두 작은지만 확인하면 됩니다.

벡터 시계를 사용하면 버전의 순서를 쉽게 파악할 수 있지만, 충돌 감지 및 해소 로직이 클라이언트에 들어가야 하고 
클라이언트 구현이 복잡해진다는 단점이 있습니다.  
또한 [서버:버전] 순서쌍 개수가 굉장히 빠르게 늘어나는 단점이 있습니다. 문제를 해결하기 위해서는
순서쌍의 개수의 임계치를 설정하고, 임계치를 넘어가면 오래된 순서쌍을 제거해야 합니다.
하지만 이렇게 하면 선후 관계가 정확하게 결정될 수 없기 때문에 충돌 해소 과정의 효율성이 낮아지게 됩니다.
하지만 아마존의 다이나모에서 이런 문제가 발생한 적 없다고 하니 아마존급이 아니면 사용해도 되지 않을까 싶습니다.

---

**장애 처리**

대다수 대규모 시스템에서 장애는 흔하게 벌어집니다. 우선 장애 감지 기법을 살펴보고 장애 해소 전략을 짚어보겠습니다.

**장애 감지**

분산 시스템에서는 서버A가 죽었다고 해서 바로 장애처리 하지는 않습니다. 정족수 합의 프로토콜 느낌처럼
다른 서버에서(보통 2대 이상) 서버A의 장애를 보고해야 해당 서버에 실제로 장애가 발생했다고 간주하게 됩니다.

<img width="306" height="311" alt="Image" src="https://github.com/user-attachments/assets/e18678d0-d5f9-496f-9d4b-fc4f365db6f5" />

서버 사이에 멀티캐스팅 채널을 구축하는 것이 서버 장애를 감지하는 가장 손쉬운 방법입니다. 서버가 늘어난다면 비효율적이겠지만요.

---

가십 프로토콜 같은 분산형 장애 감지 솔루션을 채택하면 보다 효율적으로 장애 감지가 가능합니다. 동작 원리는 다음과 같습니다.
- 각 노드는 멤버십 목록을 유지한다. 멤버십 목록은 각 멤버 ID와 그 박동 카운터(heartbeat counter) 쌍의 목록이다.
- 각 노드는 주기적으로 자신의 박동 카운터를 증가시킨다.
- 각 노드는 무작위로 선정된 노드들에게 주기적으로 자기 박동 카운터 목록을 보낸다.
- 박동 카운터 목록을 받은 노드는 멤버십 목록을 최신 값으로 갱신한다.
- 어떤 멤버의 박동 카운터 값이 지정된 시간 동안 갱신되지 않으면 해당 멤버는 장애 상태인 것으로 간주한다.

<img width="509" height="263" alt="Image" src="https://github.com/user-attachments/assets/c0ae6f35-2114-4be2-bb3a-9c1c9039d93a" />

노드 s0가 가지고 있던 멤버십 목록에서 s2가 박동 카운터가 오랫동안 증가되지 않았다는 것을 발견합니다.
이후 s0는 박동 카운터 목록을 무작위로 선택된 다른 노드에게 전달합니다.
노드 s2의 박동 카운터가 오랫동안 증가되지 않았음을 발견한 모든 노드는 해당 노드를 장애 노드로 표시합니다.

> s0가 박동 카운터가 오랫동안 증가되지 않았다는 것을 어떻게 파악하는 것인가?  
> 300정도의 수치가 부족하고, 120초 정도의 업데이트 시간의 차이가 있는데 이 정도의 수치로 장애가 발생했다고 판단할 수 있는건가?  
> [Phi Accrual Detection](https://medium.com/@arpitbhayani/phi-%CF%86-accrual-failure-detection-79c21ce53a7a)  
> 분산 시스템에서 장애 감지를 하는 방법에 대해 있었습니다. 요약하자면 수학적 기법을 활용하여 일정 시간동안 heartbeat counter가 업데이트되지
> 않았을 때 장애일 확률을 계산하여 장애를 감지 한다고 합니다. 알잘딱으로 지연된건가 네트워크 장애인가 판단한다는 의미입니다.
> 결국 300의 수치, 120초의 업데이트 지연은 예시로 든 것뿐입니다.

---

**일시적 장애 처리**

가십 프로토콜로 장애를 감지한 시스템은 가용성을 보장하기 위해 필요한 조치를 해야 합니다.  
엄격한 정족수(strict quorum) 접근법을 쓴다면, 앞서 "데이터 일관성" 절에서 설명한 대로, 읽기 / 쓰기 연산을 금지해야 할 것입니다.

느슨한 정족수(sloppy quorum) 접근법은 이 조건을 완화하여 가용성을 높입니다.
쓰기 연산을 수행할 w개의 건강한 서버와 읽기 연산을 수행할 r개의 건강한 서버를 해시 링에서 고릅니다. 장애 상태인 서버는 무시합니다.

네트워크나 서버 문제로 장애 상태인 서버로 가는 요청은 다른 서버가 잠시 맡아 처리합니다.
그동안 발생한 변경사항은 해당 서버가 복구되었을 때 일괄 반영하여 데이터 일관성을 보존합니다. 이를 위해 임시로 쓰기 연산을 처리한 서버에는
그에 관한 단서(hint)를 남겨둡니다. 이런 장애 처리 방안을 단서 후 임시 위탁(hinted handoff) 기법이라 합니다.

---

**영구 장애 처리**

영구적인 노드의 장애 상태를 처리하기 위해 반-엔트로피(anti-entropy) 프로토콜을 구현하여 사본들을 동기화시키도록 하겠습니다.
반-엔트로피 프로토콜은 사본들을 비교하여 최신 버전으로 갱신하는 과정을 포함합니다. 사본 간의 일관성이 망가진 상태를 탐지하고 전송 데이터의
양을 줄이기 위해 머클(Merkle)트리를 사용할 것이다.

머클 트리의 정의는 다음과 같습니다.
- 해시 트리라고도 불리는 머클 트리는 각 노드에 그 자식 노드들에 보관된 값의 해시, 또는 자식 노드들의 레이블로부터 계산된 해시 값을
  레이블로 붙여두는 트리

해시 트리를 사용하면 대규모 자료 구조의 내용을 효과적이면서도 보안상 안전한 방법으로 검증할 수 있다.

<img width="501" height="303" alt="Image" src="https://github.com/user-attachments/assets/160f28c8-cc98-4113-87b1-6ee6ccece9e8" />

완성된 머클 트리는 그림처럼 생성이 됩니다. 8번째 노드가 일관성이 망가진 데이터입니다.
두 트리의 루트 노드의 해시 값이 같다면 두 서버는 같은 데이터를 가지는 것으로 여길 수 있습니다.
값이 다른 경우에는 값이 다른 노드쪽을 타고 가다보면 다른 데이터를 가지는 노드를 찾을 수 있습니다.

| 구분         | 일시적 장애 (Transient Failure) | 영구적 장애 (Permanent Failure) |
| ---------- | -------------------------- | -------------------------- |
| **정의**     | 일시적으로 네트워크나 서버가 응답하지 않음    | 서버나 디스크가 물리적으로 완전히 고장남     |
| **지속 시간**  | 짧고 일시적 (보통 자동 복구 가능)       | 장기적 또는 영구적 (복구 불가, 교체 필요)  |
| **예시**     | 네트워크 지연, 재부팅 중, 일시적 과부하    | 하드웨어 손상, 디스크 불량, 서버 소실     |
| **복구 가능성** | 복구 가능 (시간 지나면 다시 살아남)      | 복구 불가능 (새 노드로 대체해야 함)      |


---

**데이터 센터 장애 처리**

데이터 센터 장애는 정전, 네트워크 장애, 천재지변 등 다양한 이유로 발생할 수 있습니다.
데이터 센터 장애를 극복하기 위해서는 여러 데이터 센터에 다중화하는 것이 중요합니다.

---

### 시스템 아키텍처 다이어그램
다음의 그림은 아키텍처 다이어그램입니다.

<img width="535" height="356" alt="Image" src="https://github.com/user-attachments/assets/8a6a25a5-da7d-44c6-a641-9bf1e32f2c46" />

- 클라이언트는 키-값 저장소가 제공하는 두가지 단순한 API인 get(key)와 put(key, value)로 통신한다.
- 중재자(coordiantor)는 클라이언트에게 키-값 저장소에 대한 프록시(proxy) 역할을 하는 노드다.
- 노드는 안정 해시의 해시 링 위에 분포한다.
- 노드를 자동으로 추가 또는 삭제할 수 있도록 시스템은 완전히 분산된다.
- 데이터는 여러 노드에 다중화된다.
- 모든 노드는 같은 책임을 지므로, SPOF(Single Point of Failure, 단일 실패 지점)는 존재하지 않는다.

> 엥 중재자는 1개 있는거 아닌가요? 그럼 단일 실패 지점되는거 아닌가요?  
> 대부분의 실제 키-값 저장소는 중재자를 없애거나 다중화하여 SPOF를 피하도록 전략을 구사합니다. 사진이 잘못된 것 같습니다.

| 시스템                 | 중재자 필요?      | 클라이언트 직접 요청? | SPOF 여부                          |
| ------------------- | ------------ | ------------ | -------------------------------- |
| **Redis (단일 인스턴스)** | ❌            | ✅            | ✅                                |
| **Redis Sentinel**  | ✅ (Sentinel) | ❌            | Sentinel 죽으면 제한적 SPOF            |
| **Cassandra**       | ❌            | ✅            | ❌                                |
| **DynamoDB**        | ❌            | ✅ (API 통해)   | ❌                                |
| **ZooKeeper**       | ✅ (Leader)   | ❌            | ⚠️ 리더 죽으면 선출 필요, 약간의 순간 중단 발생 가능 |
| **etcd**            | ✅ (Raft 리더)  | ❌            | ❌ (리더는 재선출됨)                     |



완전히 분산된 설계를 채택하였으므로, 모든 노드는
- 클라이언트 API
- 장애 감지
- 데이터 충돌 해소
- 장애 복구 메커니즘
- 다중화
- 저장소 엔진
같은 기능을 지원해야 합니다.

### 쓰기 경로
쓰기 요청이 특정 노드에 전달되면 벌어지는 일을 나타내는 구조입니다. 카산드라의 사례를 참고했습니다.

<img width="478" height="304" alt="Image" src="https://github.com/user-attachments/assets/9f73d716-0b17-411a-a5b7-a989abfe0324" />

1. 쓰기 요청이 커밋 로그 파일에 기록된다.
2. 데이터가 메모리 캐시에 기록된다.
3. 메모리 캐시가 가득차거나 사전에 정의된 어떤 임계치에 도달하면 데이터는 디스크에 있는 SSTable에 기록된다.
   Sorted String Table의 약자로 (키, 값)의 순서쌍을 정렬된 리스트 형태로 관리하는 테이블이다.

> SSTable?

### 읽기 경로
읽기 요청을 받은 노드는 데이터가 메모리 캐시에 있는지부터 살핍니다. 있는 경우에는 해당 데이터를 클라이언트에게 반환합니다.

<img width="599" height="321" alt="Image" src="https://github.com/user-attachments/assets/60c7aef7-38e4-4afb-967b-5a6a20f4364c" />

데이터가 메모리에 없는 경우에는 디스크에서 가져와야 합니다. 어느 SSTable에 찾는 키가 있는지 알아낼 방법이 필요한데,
블룸 필터(Bloom filter)가 흔히 사용됩니다.

<img width="542" height="301" alt="Image" src="https://github.com/user-attachments/assets/2d646fd0-a233-4b83-859e-19808390a6eb" />

1. 데이터가 메모리에 있는지 검사한다. 없으면 2로 간다.
2. 데이터가 메모리에 없으므로 블룸 필터를 검사한다.
3. 블룸 필터를 통해 어떤 SSTable에 키가 보관되어 있는지 알아낸다.
4. SSTable에서 데이터를 가져온다.
5. 해당 데이터를 클라이언트에게 반환한다.

> Bloom Filter? [한국어로 쓰여있음](https://sslab.dankook.ac.kr/1-6-bloom-filter/)  
> 시간 나면 읽고 정리해보겠습니다.

### 참고문헌(해놓고 안읽기)

[PACELC 이론](https://shinbe.tistory.com/entry/CAP%EC%9D%B4%EB%A1%A0%EC%9D%98-%ED%95%9C%EA%B3%84%EC%99%80-PACELC-%EC%9D%B4%EB%A1%A0-%E2%91%A0)

[Quorum 위키피디아](https://en.wikipedia.org/wiki/Quorum_(distributed_computing))

[정족수와 합의](https://krapi0314.tistory.com/75)
