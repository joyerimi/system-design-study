# 1. **처리율 제한 장치**

- 네트워크 시스템에서 **클라이언트나 서비스의 요청 속도를 제어**하는 장치
- 예시
    - 초당 2회 이상 글 작성 금지
    - IP당 하루 10개 계정 생성 제한
    - 디바이스당 주당 5회 리워드 요청 제한
- 필요성
    
    **① 보안: DoS 공격 방지**
    
    - 과도한 요청으로 자원 고갈을 방지
    - 예시
        - 트위터: 3시간에 300 트윗 제한
        - 구글 Docs: 분당 300회 읽기 제한
    
    **② 비용 절감**
    
    - 서버를 무한히 늘리지 않아도 됨
    - 중요 API에 자원을 집중 가능
    - 과금형 API 호출 수 절감
    
    **③ 시스템 안정성 유지**
    
    - 비정상 트래픽(봇, 오남용 등) 차단
    - 서버 과부하 사전 예방

---

# 2. 처리율 제한 장치의 설계 흐름

## 1단계: 문제 이해 및 설계 범위 확정

### **🔸 면접 대화 흐름 요약**

- **어떤 제어 대상?**
    - 클라이언트 측인가, 서버 측인가 → **서버 측 API 요청 제어**로 가정
- **어떤 기준으로 제한할 것인가?**
    - IP 주소? 사용자 ID? → 다양한 제어 규칙(throttling rules)을 유연하게 지원해야 함
- **시스템 규모는?**
    - 스타트업? 대기업? → **대규모 요청 처리 가능해야 함**
- **환경은?**
    - 단일 서버? 분산 시스템? → **분산 환경을 고려한 설계**
- **시스템 형태는?**
    - 독립 서비스? 어플리케이션 내 포함? → **설계자가 선택**
- **사용자 피드백은?**
    - 제한되었을 때 사용자에게 **알림 필요**

### **🔸 시스템 요구사항 요약**

| 요구사항 | 설명 |
| --- | --- |
| 정확한 요청 제한 | 설정된 요청 속도를 초과하면 확실하게 차단 |
| 낮은 응답 지연 | HTTP 응답 속도에 영향을 주면 안 됨 |
| 메모리 효율성 | 가능한 한 적은 메모리로 동작해야 함 |
| 분산 환경 지원 | 여러 서버/프로세스 간 제한 장치 상태 공유 가능 |
| 예외 처리 | 제한된 요청은 사용자에게 명확히 알려야 함 |
| 고가용성(Fault Tolerance) | 제한 장치에 문제가 생겨도 전체 시스템은 정상 작동해야 함 |

---

## 2단계: 개략적 설계안 제시 및 동의 구하기

### **🔸 처리율 제한 장치의 위치 종류**

책에서는 처리율 제한 장치의 위치를 **클라이언트 측 / 서버 측 / API 게이트웨이** 세 가지로 나눈다.

1. **클라이언트 측**
    - 클라이언트(웹/모바일 앱) 자체에서 요청 빈도를 제한하는 방식
    - **장점**
        - 네트워크 트래픽 자체 감소 가능
    - **단점**
        - 클라이언트 위변조 가능성 → 신뢰 불가
        - 다양한 클라이언트 환경에서 통일된 제어 어려움
    
    **→ 실제 제어용으로는 부적절함**
    

2. **서버 측**

서버 측 구현 방식은 다시 **2가지**로 나뉜다.

① **API 서버 내부에 직접 구현**

![Image](https://github.com/user-attachments/assets/03ede2b8-21cb-48ea-8dd8-97bc0f9df1fe)

- 요청 처리 로직 내부에서 처리율 제한 로직을 직접 구현
- **장점**
    - API별 맞춤 제어 가능
    - 유연한 커스터마이징
- **단점**
    - 중복 로직 가능성
    - 분산 시스템에서는 Redis 등 외부 저장소 필요

② **서버 앞단 미들웨어로 구현**

![Image](https://github.com/user-attachments/assets/20a8095e-9ebd-424a-b113-7ee02321a3bd)

![Image](https://github.com/user-attachments/assets/26dab1a5-6e0d-486b-b670-2a3ca3db3aad)

- API 서버 앞단에 **요청을 필터링하는 미들웨어 계층**을 두어 제한
- 예: Express/Koa 미들웨어, NGINX 등
- **장점**
    - API 서버와 분리된 요청 제어
    - 공통 로직 재사용 용이
- **단점**
    - 미들웨어가 병목 지점이 될 수 있음
    - 상태 공유 및 분산 구현 필요

3. **API 게이트웨이에 구현**

- 클라우드 기반 마이크로서비스 환경에서 가장 일반적인 방식
- 처리율 제한을 **API Gateway**(예: AWS API Gateway, Kong 등)에 설정
- **장점**
    - 인증, SSL, IP 제어 등과 함께 통합 관리 가능
    - 설정만으로 빠르게 적용 가능 (Fully Managed)
- **단점**
    - 지원되는 알고리즘/정책에 제한 있음
    - 세부 제어는 어렵거나 불가능할 수 있음

### **🔸 처리율 제한 장치의 위치 선택 가이드**

> 내부 구현은 자유도가 높지만 비용이 큼
> 
> 
> Gateway는 빠르고 안정적이지만 유연성은 떨어짐
> 
> 현재 기술 환경과 조직 역량을 고려해 **타협과 선택**이 필요함
> 
1. **현재 기술 스택 점검**
    - 사용하는 **프로그래밍 언어**와 **캐시 서비스(Redis 등)**가 서버 측 구현을 효율적으로 지원하는지 확인해야 한다.
    
    > 예: 싱글 스레드 환경에서 정밀한 제어가 필요한 경우, 비동기적 언어 사용이 유리
    > 
2. **알고리즘 자유도 확인**
    - **서버 내부**에 구현하면 → 알고리즘(토큰 버킷, 슬라이딩 윈도우 등) 선택의 **자유도**가 높다.
    - 반대로, **API Gateway 사용 시** → **제공되는 기능 안에서만** 선택 가능하므로 **제한적**이다.
3. **기존 설계와의 통합 고려**
    - 이미 **API Gateway를 도입하고**, 인증이나 IP 필터링 등의 기능도 그 안에 구성돼 있다면 → **처리율 제한도 Gateway에 포함**시키는 것이 자연스럽다.
4. **구현 리소스 고려**
    - 직접 처리율 제한 장치를 구현하려면 시간과 인력이 필요하다.
    - 인력/시간이 부족하다면 **상용 API Gateway**(AWS API Gateway, Kong 등)를 사용하는 것이 **현실적인 선택**이다.

### **❓내 생각**

최근에 프로젝트 하면서 **비회원도 포함된 조회수 증가 기능**을 구현해야 할 일이 있었다. 그땐 "하루에 한 번만 올라가면 되지" 싶어서 쿠키로 중복 체크해서 처리하려고 했다. 근데 책을 읽다 보니 "**어디서 제한을 두는 게 맞을까?**"라는 고민이 생겼다.

조회수는 조작되면 의미가 없으니까, 클라이언트에서 제어하는 건 안 되고, **API Gateway는 인증 기반 제어에 적합해서 비회원 요청에는 부적절**해 보였다. 결국 **서버 내부에서 제어하는 게 맞겠다**는 생각이 들었다.

### **🔸 처리율 제한 알고리즘**

| 알고리즘 | 개념 | 장점 | 단점 |
| --- | --- | --- | --- |
| 토큰 버킷 | 일정 주기로 토큰을 채움, 요청시 토큰 소모 | 간단, Burst 처리 가능 | 버킷 설정(Tuning)이 민감함 |
| 누출 버킷 | 큐에 쌓고 일정 속도로 처리 | 일정한 속도 유지 | 최신 요청이 늦게 처리될 수 있음 |
| 고정 윈도 카운터 | 고정 시간 창마다 카운트 증가 | 구현 쉬움 | 윈도 경계에서 폭주 가능성 |
| 이동 윈도 로그 | 요청 타임스탬프 기록 | 정확하고 정밀 | 메모리 사용 많음 |
| 이동 윈도 카운터 | 직전 시간대 요청량 평균으로 현재 판단 | 메모리 효율, 정밀도 절충 | 근사치라 느슨할 수 있음 |

### **1. 토큰 버킷(token bucket) 알고리즘**

가장 널리 쓰이는 처리율 제한(rate limiting) 알고리즘 중 하나로, Amazon, Stripe 같은 기업도 사용 중이다. 이해하기 쉽고 구현도 간단한 편이다.

**기본 원리**

![Image](https://github.com/user-attachments/assets/92903343-9fa4-4e2e-a570-19e25df4ac02)

1. **버킷**: 일정 수용량을 가진 그릇
2. **토큰 공급기**: 일정 시간마다 정해진 수의 토큰을 버킷에 채운다
    
    ![Image](https://github.com/user-attachments/assets/9f8a0a1c-3adc-45e4-9c70-b2283e55c046)
    
    - 버킷이 가득 차면 더 이상 토큰을 추가하지 않음 (초과 토큰은 버림)
3. **요청 처리**
    
    ![Image](https://github.com/user-attachments/assets/3204080e-d1f3-48d8-9c64-50d747489453)
    
    - 요청이 오면 **버킷에 토큰이 있으면** 하나 꺼내고 요청 처리
    - **토큰이 없으면** 요청은 거절(drop)됨

**핵심 파라미터**

- **버킷 크기 (capacity)**: 최대 보유 가능한 토큰 수
- **토큰 공급률 (refill rate)**: 초당 몇 개의 토큰을 채울 것인지

**적용 예시**

- 사용자당 하루에 1번 포스트 작성 가능 → 사용자별로 1개짜리 버킷 생성
- IP별로 제한 → IP별 버킷 생성
- 전체 시스템 초당 10,000 요청 제한 → 하나의 공용 버킷 사용

**장점**

- 구현이 쉽고 메모리 효율이 좋음
    
    → 이 사람한테 지금 몇 개 토큰 남았는지만 기억하면 됨
    
- **Burst traffic**(짧은 시간에 몰리는 요청)을 유연하게 처리 가능
    - 버킷에 토큰만 남아있다면 요청은 허용됨
    
    → 보통 알고리즘은 “초당 1개만 허용”처럼 바로 거절하지만, 토큰 버킷은 여유분이 있어서 갑작스런 트래픽을 버틸 수 있음
    

**단점**

- **튜닝이 어려움**
    - 버킷 크기와 공급률 설정이 까다로움
    - 트래픽 패턴을 잘 이해하고 조절해야 효과적임

### **2. 누출 버킷 알고리즘(leaky bucket) 알고리즘**

> “항상 일정한 속도로 처리하고 싶을 때 적합”하지만,
갑자기 트래픽이 몰릴 때는 최신 요청이 버려질 수 있다.
> 

FIFO 큐 기반으로 동작하는 처리율 제한 알고리즘으로, Shopify 같은 기업이 사용한다. (+ Nginx)

**토큰 버킷과 비슷하지만, 요청을 처리하는 속도가 고정되어 있다는 점이 다르다.**

**기본 원리**

![Image](https://github.com/user-attachments/assets/3dfb8476-5367-445e-9552-2032ce5c4805)

1. 요청이 도착하면, **먼저 큐가 가득 찼는지 확인**한다.
2. **빈 공간이 있으면** 큐에 요청을 추가한다.
3. **가득 찼으면** 새 요청은 거절(drop)된다.
4. 일정 시간마다 **고정 속도**로 큐에서 요청을 꺼내 처리한다.

**핵심 파라미터**

- **버킷 크기** = 큐의 최대 길이
- **처리율(outflow rate)** = 초당 몇 개 요청을 처리할지

**장점**

- **메모리 효율**: 큐 크기만 유지하면 됨
- **안정된 처리율**: 일정한 속도로 요청을 처리함
    
    → 백엔드 시스템에 안정적인 부하 유지 가능
    

**단점**

- **Burst 트래픽에 약함**: 갑자기 많은 요청이 몰리면, 큐에 쌓이고 최신 요청이 거절될 수 있음
- **튜닝 어려움**: 버킷 크기와 처리율을 잘 조절해야 함

### **❓내 생각**

처음엔 "누출 버킷은 천천히라도 계속 받는데, 토큰 버킷은 다 쏟고 나면 거절하지 않나? 그럼 버스트 트래픽에서 누출 버킷이 더 나은 거 아닌가?" 싶었다.

근데 중요한 차이는 **처리 시점**이었다.

**토큰 버킷**은 미리 쌓아둔 토큰만큼 요청을 **한꺼번에 빠르게 처리**할 수 있어서, 순간 몰리는 트래픽(Burst)에 **즉시 대응** 가능하다.

반면, **누출 버킷**은 무조건 고정 속도로만 처리해서 몰리는 순간엔 바로 밀리거나 드롭된다.

→ 결국 "얼마나 빨리 처리할 수 있느냐"가 관건이었다.

### **3. 고정 윈도 카운터(fixed window counter) 알고리즘**

가장 단순한 처리율 제한 방식 중 하나로, 시간 단위를 **고정된 윈도(window)**로 나누고 각 윈도마다 **카운터**를 두어 요청 수를 제한한다.

**작동 방식**

![Image](https://github.com/user-attachments/assets/0a7ba6c5-1bd3-41c0-9a6a-f3e2d1fdc012)

1. 타임라인을 일정 간격(예: 1초, 1분)으로 나눔
2. 각 구간(윈도)에 도달한 요청 수를 카운팅
3. **설정된 한도를 넘으면** 해당 윈도 내 추가 요청은 모두 거절됨

예: “초당 3개 요청 허용”이면 → 매초 카운터가 3이 되면 그 뒤 요청은 drop

**문제점: 윈도 경계 효과**

![Image](https://github.com/user-attachments/assets/6d6ebc2f-85ea-4d65-8388-8386cf24ee63)

윈도 경계에 몰리는 요청은 시스템 처리량을 **의도 이상으로 증가시킬 수 있음**

- 예
    - 1분당 5개 제한이지만 59초~1초 경계에 각각 5개씩 요청하면 → **총 10개 처리**됨

**장점**

- 아주 간단하고 구현 쉬움
- 메모리 효율 좋음 (카운터만 유지)
- 일정한 트래픽이 반복되는 패턴에 적합 → 매초 3건씩 꾸준히 들어오면, 딱 3건만 받고 나머지는 드롭

**단점**

- **윈도 경계에서의 요청 몰림 현상** 때문에 처리율이 실제보다 커질 수 있음
- 버스트 트래픽엔 부적합
    
    → 윈도 경계 효과 때문에 실제 처리율이 기대치를 넘길 수 있으므로 버스트 트래픽에 유연하게 대응하지 못함
    

### **4. 이동 윈도 로깅(sliding window log) 알고리즘**

고정 윈도우 알고리즘의 **단점을 보완**하기 위해 만들어진 방식으로, 윈도우 경계 효과 없이 **정확한 처리율 제한**이 가능하다.

**동작 원리**

![Image](https://github.com/user-attachments/assets/8c025b47-cf76-49d3-9890-1abaff870fbf)

1. **요청마다 timestamp 기록**
    - Redis의 `sorted set` 같은 캐시에 저장
2. **요청 도착 시**
    - 현재 시간 기준 **윈도우 범위 밖의 timestamp 제거**
    - 최신 요청 timestamp를 **log에 추가**
    - log의 크기가 허용량 이하면 → 요청 허용
    - 크기를 초과하면 → 요청 거절

**장점**

- 윈도우 경계에 상관없이 **언제든 정확한 요청 수 제한**
- 실제 트래픽 패턴을 정확히 반영 가능

**단점**

- **모든 요청 timestamp를 저장**하므로 **메모리 사용량이 큼**
- 구현 복잡도와 연산 비용도 상대적으로 높음

### **❓내 생각**

슬라이딩 윈도우 로깅 알고리즘은 보통 **거절된 요청의 타임스탬프까지 저장**한다.

근데 난 “**왜 굳이 실패한 요청까지 저장하지?**”라는 의문이 들었다.

알고리즘의 기본 가정은 “요청 자체가 리소스를 소비하니까, 성공 여부와 관계없이 모두 제한해야 한다”는 건데,

정책에 따라 “**성공한 요청만 제한**”하고 싶을 수도 있다. 그렇다면 굳이 실패한 요청까지 기록할 필요는 없다.

### **5. 이동 윈도 카운터(sliding window counter) 알고리즘**

고정 윈도 카운터의 단점(경계 밀집 문제)과 슬라이딩 윈도 로깅의 단점(메모리 부담)을 보완한 절충형 알고리즘이다.

**기본 원리**

![Image](https://github.com/user-attachments/assets/1d0a4a04-05ca-4850-b62f-6a48c2f84d4f)

- 현재 시점에서 직전 윈도와 현재 윈도에 걸친 요청 수를 계산한다.
    - 현재 윈도 요청수 + 직전 윈도 수 요청 수 * 이동 윈도와 직전 윈도가 걸치는 비율
- 예: "1분당 7개"가 한도일 때,
    - 직전 1분에 5개, 현재 1분에 3개 요청이 있었다면,
    - 현재 1분이 30% 진행됐다면: `3 + 5 * 0.7 = 6.5 → 내림하여 6`
- 한도(7)를 넘지 않으므로 해당 요청은 허용된다.

**장점**

- **버스트 트래픽에도 유연하게 대응** 가능
- 고정 윈도보다 **훨씬 정교한 제어**
- 슬라이딩 로깅보다 **메모리 효율이 좋음**

**단점**

- **직전 윈도 요청이 균등 분포되었다고 가정**하기 때문에 다소 느슨할 수 있다.
    - 하지만 실험에 따르면 실제 오차는 0.003% 수준으로 거의 무시 가능함 (Cloudflare 실험 기준)

### **🔸 개략적 아키텍처**

**핵심 아이디어**

- 특정 대상(사용자, IP, API 엔드포인트, 서비스 단위 등)에 대해 **요청 수를 카운팅**하고,
- 그 수가 **정해진 임계값(threshold)을 넘으면** 추가 요청을 차단한다.

**어디에 카운터를 저장할까?**

- **DB는 느리기 때문에 부적절**
- **메모리 기반 캐시(예: Redis)** 가 적합
    - 빠르고, TTL 기반 만료 정책이 있음
    - 명령어 예시
        - `INCR`: 카운터 값 +1
        - `EXPIRE`: TTL 설정

**기본 구조**

![Image](https://github.com/user-attachments/assets/8d3293d4-d51b-4d05-ae3e-af8a7e01575e)

**동작 흐름**

1. 클라이언트 요청이 **미들웨어**로 먼저 들어옴
2. 미들웨어는 Redis에서 해당 요청자에 대한 카운터 값을 조회
3. 임계값을 초과했다면 → 요청 거절
4. 임계값 이하라면 → 카운터 증가 후 API 서버로 전달

**장점**

- 빠른 응답 처리 가능
- TTL 덕분에 **시간 단위 제어** 구현이 간단
- 구조가 단순해 다양한 알고리즘 적용이 쉬움

---

## 3단계: 상세 설계

### 1. 처리율 제한 규칙(Rate Limit Rule)

처리율 제한 규칙(rate limit rule)은 **도메인 + 조건(descriptor) 조합**으로 정의된다.

**예시**

1. **메시징 시스템**
    
    ```yaml
    domain: messaging
    descriptors:
      - key: message_type
        value: marketing
    rate_limit:
      unit: day
      requests_per_unit: 5
    ```
    
    - 하루에 **마케팅 메시지 5건**까지만 허용
2. 인증 시스템
    
    ```yaml
    domain: auth
    descriptors:
      - key: auth_type
        value: login
    rate_limit:
      unit: minute
      requests_per_unit: 5
    
    ```
    
    - 클라이언트는 **1분에 최대 5번**만 로그인 시도 가능

**저장 방식**

- 이런 규칙은 보통 **설정 파일(configuration file)** 형태로 **디스크에 저장**
- 시스템 시작 시 또는 주기적으로 읽어서 **캐시에 로딩(Redis 등)**

### 2. 처리가 제한된 요청의 처리 전략

### **🔸** 요청이 제한을 초과했을 때

- 제한 초과 요청은 기본적으로 **HTTP 429: Too Many Requests** 에러로 응답
- 경우에 따라선 요청을 **메시지 큐에 저장했다가 나중에 처리**할 수도 있음
    
    예: 주문 요청 등은 부하가 줄었을 때 다시 처리
    

### **🔸** 클라이언트에게 알려주는 HTTP 헤더

처리율 제한 정보는 **HTTP 응답 헤더**로 전달된다.

| 헤더명 | 의미 |
| --- | --- |
| `X-RateLimit-Remaining` | 현재 윈도 내 남은 요청 가능 수 |
| `X-RateLimit-Limit` | 윈도 당 허용된 최대 요청 수 |
| `X-RateLimit-Retry-After` | 제한 안 걸리려면 몇 초 후 다시 시도해야 하는지 |

### **🔸** 시스템 동작 구조

![Image](https://github.com/user-attachments/assets/240092bd-1ffe-407e-b7d2-7209a2df7126)

**요청 흐름**

1. 클라이언트가 요청
2. **미들웨어**가 먼저 요청 수 제한 여부 확인
3. 제한 초과 여부 판단은
    - **디스크에서 로딩한 캐시된 규칙**
    - **Redis에서 가져온 카운터 및 timestamp** 기반
4. 결과에 따라
    - 정상 처리: **API 서버로 전달**
    - 초과 요청: **HTTP 429 응답** 또는 **큐에 저장**

### 3. 분산 환경에서의 처리율 제한 기법

대규모 시스템에서는 요청을 분산 처리하기 위해 여러 대의 **처리율 제한 미들웨어 서버**를 둔다. 이들은 실제 요청을 처리하는 **웹 서버(API 서버)** 앞단에서 트래픽을 조절하는 역할을 한다.
하지만 이처럼 **여러 인스턴스의 처리율 제한 장치 서버**가 동시다발적으로 요청을 처리할 경우, 두 가지 문제가 생길 수 있다. **경쟁 조건**과 **동기화 문제**다.

### **🔸** 문제 1: 경쟁 조건(Race Condition)

여러 대의 **처리율 제한 장치 서버**가 동시에 **하나의 Redis 서버**에 요청 수를 기록하려 할 때, 상태가 꼬일 수 있는 문제다.

**문제 상황**

![Image](https://github.com/user-attachments/assets/3bbf86d2-3c54-477b-aea7-9c8676d53ffb)

- 여러 서버가 동시에 Redis에서 같은 카운터 값을 읽고 1씩 증가시키는 경우
- `counter: 3` → 요청 1, 2가 동시에 읽고 `4`로 설정 → 실제론 `5`가 되어야 함

**해결책**

- 전통적 방법: **Lock** 사용 (하지만 성능 저하 문제 있음)
- **추천 방법**
    1. **Lua 스크립트**: 여러 Redis 명령을 **원자적으로 묶어서 실행** 가능
        
        → `GET` → 검사 → `INCR` → `EXPIRE` 등 한 번에 실행
        
        → 요청 처리 중 **경쟁 조건(race condition)** 없이 **정확하게 한 요청씩만 반영**
        
    2. **Sorted Set** 구조 활용: 정렬된 요청 로그로 제한 판단
        
        → **요청 시간(timestamp)** 기준으로 정렬
        
        → 슬라이딩 윈도우 기반으로 **요청 개수 정확히 계산 가능**
        

### **❓내 생각**

**왜 Sorted Set만 쓰면 경쟁 조건이 해결된다는 걸까?**

내가 보기엔, Sorted Set 전략만으로는 부족하다. ZREMRANGEBYSCORE → ZCOUNT → ZADD 같은 명령이 순차적으로 실행되는데, **여러 클라이언트가 동시에 요청하면 중간에 다른 실행이 끼어들 수 있어서** 여전히 경쟁 조건이 발생한다.

예를 들어

1. A와 B가 거의 동시에 `ZREMRANGEBYSCORE` 수행
2. A가 `ZADD`, B가 `ZADD`
3. A가 `ZCOUNT`, B도 `ZCOUNT`
    
    → 둘 다 제한 내라고 판단할 수 있음
    

즉, **완전히 안전하려면 여러 명령을 '한번에' 실행해야 함**.

- Redis는 단일 스레드라서 **Lua로 여러 명령을 하나의 스크립트 안에 묶어 실행하면**, 그 사이에 다른 클라이언트가 끼지 못함. 즉 **원자적 실행**이 보장됨 .
- Sorted Set 전략 쓰더라도, 반드시 **ZREMRANGEBYSCORE → ZCOUNT → 조건 체크 → ZADD**를 모두 Lua 안에서 실행해야 경쟁 문제 없이 정확하게 동작함.

**락 대신 Lua가 더 나은 이유는 뭘까?**

- 락은 성능 병목을 만들 수 있고, 획득/해제 비용도 있음.
- 반면 Lua 스크립트는 **Redis 단일 스레드의 특징을 살려**, 별도 락 없이 **원자적으로 처리**할 수 있어 경량하고 빠름.
- 락은 경우에 따라 유용하지만, Redis 기반 제한 로직에는 **Lua 스크립트가 효율성과 정확성 모두 충족**시킴

### **🔸** 문제 2: 동기화(Synchronization)

여러 대의 **처리율 제한 장치 서버**가 서로 독립적으로 상태를 관리할 경우, 동일한 사용자의 요청을 정확히 제한하지 못하는 문제다.

**문제 상황**

![Image](https://github.com/user-attachments/assets/439e1d20-7c9f-4681-a24c-99cf14204a2a)

- 여러 대의 미들웨어 인스턴스가 처리율 제한을 각각 따로 관리하면, 요청 제한을 정확히 수행할 수 없음

**비효율적인 방법**

- **Sticky Session**: 특정 클라이언트가 항상 같은 인스턴스로 가도록 설정
    - 확장성과 유연성 낮음

**효율적 해결책**

- **중앙 집중형 저장소 사용 (예: Redis)**
    
    ![Image](https://github.com/user-attachments/assets/c3967e63-9182-44b8-ba90-7beb081adf3c)
    
    → 모든 인스턴스가 동일한 제한 상태 공유 가능
    

### 4. 구체적인 설계와 성능 최적화 방안, 모니터링 방안

### **🔸 성능 최적화**

처리율 제한 시스템의 성능은 분산 환경에서 특히 중요하며, 아래 두 가지 측면에서 개선할 수 있다.

### 문제 1: 지연(latency)

- **문제**: 사용자와 데이터 센터 간 거리가 멀면 응답 속도가 느려짐
- **해결책**
    - **에지 서버(Edge Server)** 배치
    - 사용자와 가까운 위치에서 요청을 처리하여 지연 최소화
    - 예: Cloudflare는 전 세계 194개 에지 서버 운영

### 문제 2: 데이터 동기화

- **문제**: 여러 지역에 걸친 서버 간 **요청 제한 상태 공유** 필요
- **해결책**
    - **최종 일관성(Eventual Consistency)** 모델 적용
    - 제한 상태를 실시간으로 완벽하게 맞추기보다, 약간의 지연을 허용
    - 실제 서비스에서 허용 가능한 수준의 오차

지연을 줄이기 위해 **지리적 분산 처리**, 일관성을 유지하기 위해 **완화된 동기화 전략**을 사용하는 것이 핵심이다.

### **🔸 모니터링**

처리율 제한 시스템이 **정상적이고 효율적으로 작동**하는지를 확인하기 위해 **모니터링이 필수**이다. 모니터링은 단순 로그 수집을 넘어서, **정책의 실효성을 검증하고 트래픽 패턴 변화에 대응**하기 위한 핵심 수단이다.

### 주요 체크 항목

1. **채택한 알고리즘이 효과적인가?**
    
    → 예: 누출 버킷, 토큰 버킷, 슬라이딩 윈도 등
    
2. **정의한 제한 규칙이 적절한가?**
    
    → 지나치게 빡빡하면 유효 요청도 차단됨
    

### 조정 시나리오

- 유효 요청이 과도하게 드롭된다면?
    
    → **규칙 완화 필요**
    
- 이벤트 등으로 트래픽이 갑자기 몰릴 때 처리 효율이 낮다면?
    
    → **알고리즘 변경 고려 (예: 토큰 버킷으로)**
    

## 4단계: 마무리

아래는 추가로 생각해볼 거리 ~

### **🔸 하드 vs 소프트 처리율 제한**

- **하드(Hard) 처리율 제한**
    - **정의**: 설정된 임계치를 **절대 초과할 수 없는** 제한 방식
    - **예시**: 분당 100건 제한이면, 101번째 요청은 반드시 거절됨
    - **장점**: 시스템 보호 측면에서 매우 안전함
    - **단점**: 짧은 시간 동안의 **버스트 트래픽**도 유연하게 처리하지 못함
- **소프트(Soft) 처리율 제한**
    - **정의**: **일시적으로 임계치를 초과할 수 있는** 제한 방식
    - **예시**: 분당 100건 제한이지만, 5~10건 정도는 초과 허용 가능
    - **장점**: 버스트 트래픽이나 중요 요청에 유연하게 대응 가능
    - **단점**: 과도한 요청이 계속되면 시스템 과부하 위험 존재

### 🔸 **다양한 계층에서의 처리율 제한**

- **현재 다룬 내용은 HTTP 계층 중심** (OSI 7계층 중 7계층: Application Layer)
    - 사용자 인증, API 호출 등에 적용되는 가장 일반적인 처리율 제한 위치
- **다른 계층에서도 처리율 제한 가능**
    - 예: OSI 3계층 (Network Layer) → **IP 기반 트래픽 제한**
    - 방법: `iptables`를 이용한 IP 단위 트래픽 필터링
        - 예: 특정 IP가 초당 10개 이상 패킷을 보내면 차단
- **왜 다른 계층에서도 적용하나?**
    - 시스템 보호 목적이 다름
        - Application 계층: **비즈니스 로직 보호**
        - Network 계층: **네트워크 자원 보호** (DDoS 방어 등)

### 🔸 **클라이언트 측 전략**

클라이언트에서 처리율 제한을 감지하고 대응하도록 설계하면 사용자 경험을 향상시킬 수 있다.

- **캐시로 API 호출 최소화**
    - 동일 데이터를 반복 요청하지 않도록 **브라우저 캐시, 앱 캐시** 활용
    - 예: 게시판 목록은 새로고침 없이 일정 시간 동안 캐시 사용
- **임계치 고려한 트래픽 제어**
    - 처리율 제한이 분당 100건이라면, **요청 간격 조절**로 초과 방지
    - 예: 타이핑 시 매 글자마다 API 호출 대신 **debounce** 처리
- **예외 처리 및 백오프 전략**
    - 429 Too Many Requests 응답 수신 시, **일정 시간 대기 후 재시도**
    - **지수 백오프(Exponential Backoff)** 전략 적용 가능
        - 예: 재시도 간격을 1초 → 2초 → 4초... 식으로 증가시킴
    - **사용자에게 명확한 메시지 제공**: 요청 제한 상태 알림

---

# 3. 회고

예전엔 **”시스템 전체 관점에서 설계한다”**는 게 뭔 말인지 사실 좀 모호했다. 그런데 이번 내용을 공부하면서, **요청 흐름을 어디서부터 제어하고, 어떤 계층에 로직을 두고, 분산 환경에서는 어떻게 일관성을 유지할지** 같은 **전체적인 시야에서 설계하는 감각**이 조금은 생긴 것 같다.

그리고 3장 참고해서 실제로 면접처럼 한번 **처리율 제한을 직접 설계해보는 연습**을 해보면, 이런 흐름이 머릿속에 더 명확하게 정리될 것 같고, 좋은 복습이 될 것 같다. (물론 오픈북 말고, 손으로 그려가면서)

또, 예전에 구현했던 **조회수 증가 기능**도 4장 참고해서 다시 설계해보면, 좋을 것 같다.