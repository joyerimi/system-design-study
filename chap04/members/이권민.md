# 가상 면접 사례로 배우는 대규모 시스템 설계 기초(4장)

스터디 날짜: 2025년 7월 9일

# 처리율 제한장치

## 처리율 제한장치란

- 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치이다.
- 추적 대상별로 요청에 대한 카운터를 두고, 카운터 값이 한도를 넘어가면 거부한다.

## 처리율 제한장치의 장점

- DoS 공격에 대한 자원 고갈(Resource Stravation)을 방지한다.
- 비용을 절감한다.
    - 추가 요청의 수를 제한하기 때문에 서버를 많이 두지 않아도 된다.
    - 우선순위가 높은 API에 더 많은 자원을 할당할 수 있다.
    - third party api 호출을 줄여서 불필요한 과금을 피할 수 있다.
- 서버 과부하를 막는다.

## 종류

- 클라이언트 측 제한장치
- 서버 측 제한장치

## 제어 규칙(throttling rules)

- 추적대상
    - IP 주소
    - 사용자 ID
- 카운팅 방법
    - redis를 사용한 메모리 기반 count

## 처리율 제한 장치의 위치

![image](https://github.com/user-attachments/assets/f43a9233-7117-41c7-8eba-2e4cfbfca5d2)


물리적 위치

- 디스크 vs 메모리
    - 메모리 승. 더 빠름. TTL 지원함

논리적 위치

| 위치 | 장점 | 단점 |
| --- | --- | --- |
| **클라이언트 측** | - 네트워크 트래픽 절감<br/>- 서버 왕복 없이 빠른 피드백 제공 | - 코드 변조·우회 가능<br/>- 플랫폼별 중복 구현·유지 보수 필요 |
| **서버 측** | - 실제 처리된 요청만 정확히 집계<br/>- 인증·인가 등 비즈니스 컨텍스트와 연동 용이 | - 애플리케이션 성능 부담 증가<br/>- 마이크로서비스마다 중복 구현<br/>- 분산 환경 동기화 필요 |
| **미들웨어 측** | - 애플리케이션 코드 변경 없이 중앙에서 정책 관리<br/>- 서비스 횡단적 일관된 제한 적용<br/>- Redis 등으로 확장성·고가용성 확보 | - 요청 경로에 추가 네트워크 홉 발생<br/>- 별도 컴포넌트 운영·모니터링 복잡도 증가<br/>- 미들웨어 장애 시 전체 영향 가능성 |

MSA에서는 보통 처리율 제한 장치는 API Gateway에 구현된다.

- API Gateway는 다음과 같은 역할을 한다.
    - 처리율 제한
    - SSL
    - 사용자 인증 authentication
    - IP 허용 목록 관리
    - 등등
    

## 요구사항

- 설정된 처리율을 초과하는 요청은 정확하게 제한
- 낮은 응답시간: 처리율 제한 장치가 HTTP 응답시간에 나쁜 영향을 주어서는 안된다.
- 가능한 한 적은 메모리 사용
- 분산형 처리율 제한: 하나의 처리율 제한 장치를 여러 서버나 프로세스에서 공유한다.
- 예외 처리: 요청이 제한되었을 때 사용자에게 분명하게 보여주어야 한다.
- 높은 fault tolerance: 처리율 제한 장치에 장애가 생기더라도 전체 시스템에 영향을 주어서는 안된다.

## 처리율 제한 알고리즘

### 토큰 버킷

![image 1](https://github.com/user-attachments/assets/ecacb2e2-1058-4ff4-85e3-a09a587d9f74)


- 아마존과 스트라이프에서 사용
- 토큰 버킷이라는 개념이 존재
- 토큰 버킷은 크기가 제한되어 있으며 꽉 찰 때까지 토큰 공급기에서 토큰을 추가받음
- 각 요청이 처리될 때마다 토큰을 하나씩 사용함
    - 이때 요청이 들어오면 토큰이 충분한지 검사함
        - 토큰이 없으면 요청은 버려짐
        - 토큰이 있으면 요청을 시스템에 전달함

버킷의 수는 몇 개나 있어야 하나?

- 일반적으로 endpoint마다 별도의 버킷을 둠
- 하지만 IP 주소별로 처리율을 제한한다면 IP 주소마다 버킷을 할당함
- 시스템의 전체 처리율을 초당 10,000개로 제한하고 싶다면, 모든 요청이 하나의 버킷을 공유하게 해야함

장점

- 구현이 쉬움
- 메모리를 효율적으로 사용함
    - 왜? 아마도 버킷 크기가 제한되어 있어서 그런듯
- 짧은 시간에 집중되는 트래픽도 처리 가능함

단점

- 버킷 크기와 토큰 공급률이라는 파라미터를 적절히 튜닝하는 것이 어려움

### 누출 버킷

![image 2](https://github.com/user-attachments/assets/86d1d948-730c-4e29-861f-d61167721e10)


- 토큰 버킷과 비슷하지만, 요청 처리율이 고정돼있음
- 누출 버킷은 보통 FIFO 큐로 구현함
- 요청이 도착하면 큐에 넣음
    - 이때 큐가 가득차있다면 그냥 요청을 버림
- 지정된 시간마다 큐에서 요청을 꺼내어 처리함

파라미터

- 버킷 크기
- 처리율

장점

- 큐의 크기가 제한되어 있어 메모리 사용량 측면에서 효율적임
- 고정된 처리율을 가지고 있기 때문에 안정적 출력이(stable outflow rate) 필요한 경우에 적합함

단점

- 단시간에 많은 트래픽이 몰리는 경우 큐에 오래된 요청들이 쌓이게 됨
    - 이 요청들이 제때 처리되지 못한다면 새로운 요청은 버려짐
- 파라미터 튜닝하는 것이 어려울 수 있음

### 고정 윈도 카운터

![image 3](https://github.com/user-attachments/assets/738d3137-337b-461f-9dde-05905183ed56)


- 타임라인을 고정된 간격의 window로 나누고, 각 윈도우마다 counter를 붙임
    - 요청이 접수될 때마다 counter의 값이 1씩 늘어남
    - counter의 값이 threshold에 도달하면 새로운 요청은 버려짐
- 각 윈도우의 경계에 요청이 몰리게 된다면 원하는 처리율보다 최대 2배 이상 처리하게 됨
    - 예를 들어서 1분마다 5개씩만 처리한다고 할 때
        - 30초부터 1분까지 5개가 들어오고 1분부터 1분 30초까지 5개가 들어온다면, 고정 윈도우에서는 각 윈도우 내에서 5개씩의 요청밖에 없지만,
        30초부터 1분 30초까지 사이 1분간의 요청은 10개가 들어옴
        - 결론적으로 1분 안에 10개의 요청을 처리하게 됨

장점

- 메모리 효율이 좋음 → 고정된 크기의 윈도우를 가지고 요청을 처리하기 때문
- 직관적이라 이해하기 쉬움
- 윈도우가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴을 처리하기에 적합함
    - 시간마다 주기적으로 들어오는 트래픽 패턴이려나?

단점

- 윈도우 경계 부근에 일시적으로 많은 트래픽이 몰리는 경우 기대했던 시스템의 처리 한도보다 많은 양의 요청을 처리하게 됨

### 이동 윈도  로그

![image 4](https://github.com/user-attachments/assets/ed5359f9-563a-4058-b7c2-7076a4c6619f)


- 고정 윈도우 카운터의 문제를 해결함
- 요청의 타임스탬프를 추적하여 (일반적으로)redis의 sorted set에 보관함
- 새 요청이 오면 만료된 타임스탬프는 제거함
    - 만료됨 타임스탬프란? 윈도우의 시작 시점보다 오래된 값
- 새 요청의 타임스탬프를 **무조건** 로그에 추가함
    - 로그의 크기가 허용치보다 작거나 같으면 시스템에 전달함
    - 그 외의 경우에는 처리 거부
    - 처리가 되든 안되든 로그에 추가하는데 이는 처리율 제한 장치가 얼마나 많은 요청을 받았는지가 중요하기 때문임

장점

- 허용되는 요청의 수는 시스템의 처리율 한도를 넘지 않음

단점

- 거부된 요청의 타임스탬프도 보관하기 때문에 다량의 메모리를 사용함

### 이동 윈도 카운터

![image 5](https://github.com/user-attachments/assets/5ae8c632-e76e-484f-bb35-86fe0ef5dd4f)

처리율 한도가 분당 5개라고 돼있는데, 7개가 맞는듯

- 고정 윈도우 카운터 + 이동 윈도우 로깅 알고리즘
- 현재 고정 윈도우 + 직전 고정 윈도우 * (현재 이동 윈도우와 직전 고정 윈도우가 겹치는 비율) = 현재 이동 윈도우 요청 수
    - 3 + 5 * (7/10) = 3 + 3.5 = 6.5

장점

- 이전 시간대의 평균 처리율에 따라 현재 윈도우의 상태를 계산하므로 짧은 시간에 몰리는 트래픽에도 잘 대응한다.
    - 평균 처리율? 직전 고정 윈도우 * (현재 이동 윈도우와 직전 고정 윈도우가 겹치는 비율)
- 메모리 효율이 좋다.

단점

- 이전 시간대에 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하기 때문에 다소 느슨하다.

## 초과 트래픽 처리

- 요청이 한도에 걸리면 HTTP 429(too many requests)를 헤더와 함께 응답
    - X-Ratelimit-Remaining: 윈도우 내에 남은 처리 가능 요청의 수
    - X-Ratelimit-Limit: 매 윈도우마다 클라이언트가 전송할 수 있는 요청의 수
    - X-Ratelimit-Retry-After: 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알림

## 상세 설계

![image 6](https://github.com/user-attachments/assets/0561c274-cd08-49e3-be7d-722718742af0)


- 처리율 제한 규칙은 디스크에 보관하고, 작업 프로세스는 수시로 규칙을 디스크에서 읽어 캐시에 저장함
- 옵션2의 경우 처리율을 초과하는 요청의 경우 일단 메시지 큐에 보관하고 202 accepted와 같은 응답을 보낼 수 있음. 나중에 여유가 있을 때 subscribe 하여 요청을 처리

## 분산환경에서의 처리율 제한 장치

문제점 두가지

- 경쟁 조건(race condition)
- 동기화(sychronization)

### 경쟁조건

![image 7](https://github.com/user-attachments/assets/02b70971-7d1a-47d8-ad7e-253269f1e7ff)


해결책

- lock 사용 → overhead가 너무 큼. 성능을 상당히 떨어트림
- 루아 스크립트 사용 → 복수 커맨드를 원자적으로 실행 ⇒ 완전한 경합 방지
    - redis는 싱글 스레드 기반이기 때문에 가능. lock을 사용하는 게 아니고 단순히 다음 요청을 blocking하는 것
    - 다만 스크립트가 너무 길면 오히려 전체 서비스에 지연이 생김
- redis의 sorted set → 타임스탬프 기반 슬라이딩 로그 구조 ⇒ 윈도우 단위 정확한 카운팅

### 동기화

![image 8](https://github.com/user-attachments/assets/e5b811ca-452a-4509-9c59-526d71c87ff5)


해결책

- sticky session → 확장 가능하지도 않고, 유연하지도 않음
- redis 같은 중앙 집중형 데이터 저장소 → 왜 좋음???
    - 단일 진실 소스
    - 원자적 연산
    - TTL 자동 만료
    - 높은 처리량
    
    ![image 9](https://github.com/user-attachments/assets/b1a8d981-3286-42fa-aaac-3c8291ed6c7d)

    

## 성능 최적화

- edge server를 사용해 사용자의 트래픽을 가까운 곳으로 전달하여 지연시간을 줄임

## 모니터링

모니터링을 하는 이유

- 처리율 제한 알고리즘이 효과적인지 검증
- 정의한 처리율 제한 규칙이 효과적인지 검증

## 추가적으로 공부할 것

- hard vs soft 처리율 제한
- OSI의 다양한 계층에서의 처리율 제한
- 처리율 제한을 회피하는 법 ← 클라이언트의 측면에서
