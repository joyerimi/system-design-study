# 처리율 제한 장치의 설계
### 처리율 제한 장치란?
클라이언트 또는 서비스가 보내는 트래픽의 처리율(rate)를 제어하기 위한 장치입니다.
제한 장치에 정의된 임계치(threshold)를 넘어서는 행동이 감지되면 이후의 요청은 모두 중단됩니다.
- HTTP의 경우 특정 기간 내에 전송되는 클라이언트의 요청 횟수를 제한할 수 있습니다.
  - 사용자는 초당 2회 이상 새 글을 올릴 수 없다.
  - 같은 IP 주소로는 하루에 10개 이상의 계정을 생성할 수 없다.
  - 같은 디바이스는 주당 5회 이상 리워드를 요청할 수 없다.

### 제한 장치의 이점
- DoS 공격에 의한 자원 고갈 방지가 가능합니다.
  - 트위터의 경우 3시간 동안 300개의 트윗만 올릴 수 있다.
  - 구글 독스 API는 사용자당 분당 300회의 read 요청만 허용한다.

> DoS 공격(Denial of Service Attck) : 서버, 네트워크 웹사이트 같은 서비스에 과도한 요청을 보내 정상적인 사용자가 이용하지 못하게 하는 공격
> 수많은 컴퓨터(좀비 PC)를 사용하는 경우를 DDoS(Distributed DoS)라고 한다.

- 비용 절감이 됩니다. 첫 번째로 추가 요청에 대해 처리를 하지 않아도 되므로 서버 유지 부담이 적습니다. 두 번째로, third - party API를 호출하는 경우 요청을 제한시켜 비용을 아낄 수 있습니다.
- 서버 과부하를 막습니다. 봇에서 오는 트래픽이나 사용자의 잘못된 이용으로 발생하는 트래픽을 걸러낼 수 있습니다.

## 1단계 : 문제 이해 및 설계 범위 확정
책 이름에 걸맞게 가상 면접 사례로 시작합니다.
지원자는 면접관과의 대화를 통해 문제 파악 및 설계에 대한 근거를 도출해냅니다.
요약된 예시는 다음과 같습니다.

1. 설정된 처리율은 정확하게 제한합니다.
2. 낮은 응답 시간 : 이 처리율 제한 장치는 HTTP 응답시간에 나쁜 영향을 주면 안됩니다.
3. 가능한 적은 메모리를 써야 합니다.
4. 분산형 처리율 제한 : 하나의 처리율 제한 장치를 여러 서버나 프로세스에서 공유해야 합니다.
5. 예외 처리 : 요청이 제한되었을 때 사용자에게 알려야 합니다.
6. 높은 결함 감내성 : 제한 장치에 장애가 생기더라도 전체 시스템에 영향을 주어선 안됩니다.

2, 3, 6번의 경우 질문에서 유도된 내용이 아니여서 처리율 제한 장치 설계 시 기본적으로 고려해야하는 부분이라고 파악했습니다.

## 2단계 : 개략적 설계안 제시 및 동의 구하기
### 처리율 제한 장치를 어디에 둘 것인가?
일반적으로 클라이언트측은 요청이 쉽게 위변조가 가능하여 안정적으로 처리하지 못합니다. 따라서 서버 측에 제한 장치를 두거나
미들웨어를 만들어 요청이 미들웨어를 거치게 하여 요청을 통제하도록 하는 것입니다.

![image](https://github.com/user-attachments/assets/259cd35e-6463-4677-aff6-b551bac327fb)

처리율 제한 장치의 위치는 정답이 없습니다. 회사의 현재 기술 스택, 인력, 우선순위, 목표에 따라 달라질 수 있습니다.
일반적으로 적용될 수 있는 가이드라인은 다음과 같습니다.
- 현재 사용하는 언어가 서버 측 구현을 지원하기 충분할 정도로 효율이 높은지 확인해야합니다.
- 필요에 맞는 처리율 제한 알고리즘을 찾아야 합니다.
- 처리율 제한 서비스 개발은 시간이 많이 필요합니다. 상용 서비스를 이용해야 할 수 있습니다.

#### 나의 질문 : 클라이언트 측에서 할 수 있는 제한율 처리 장치??
> 버튼을 누르면 3초간 못누르게 하거나 스로틀링, 디바운싱을 적용하면 사용자의 잘못된 이용은 어느정도 막을 수 있다고 생각한다.
> 다만 클라이언트의 경우 코드 위변조의 위험성이 항상 존재하기 때문에, 서버 측(or 미들웨어 사용)에서도 공격에 대한 예방이 필요하다.

#### 나의 질문 : 언어에 따른 효율??
> 처리율 제한 장치의 도입은 기본적으로 요청 처리량이 높을 때 도입을 고민하게 될텐데, 언어 자체가 고속 처리에 부적합(Python)한 경우는
> redis를 도입하여 구현하기도 한다.
> 또한 많은 사람이 사용하는 언어일수록 rate limit 관련 오픈소스가 풍부하여 서비스 개발이 비교적 쉬울 수 있다.

### 처리율 제한 알고리즘
처리율 제한을 실현하는 알고리즘은 다양합니다. 특성을 이해하고 내 서비스/상황에 알맞는 알고리즘을 선택하는 것이 중요합니다.

#### 토큰 버킷
![image](https://github.com/user-attachments/assets/a0e8cb4a-18ea-4a57-a2e4-8c09d275f358)


토큰 버킷은 지정된 용량을 갖는 컨테이너입니다. 이 버킷에는 사전에 설정된 양의 토큰이 주기적(ex. 1초에 2개)으로 채워집니다.
버킷이 꽉 차게되면 토큰은 추가하지 않고 버립니다. 요청이 들어오게 되면, 토큰 버킷을 확인하여 토큰이 있다면 요청을 처리하고
토큰이 없다면 요청을 버립니다.

이 알고리즘은 2개의 인자가 필요합니다.
1. 버킷 크기 : 버킷에 담을 수 있는 토큰의 최대 개수
2. 토큰 공급률 : 초당 몇 개의 토큰이 버킷에 공급되는가

버킷을 몇 개 사용해야 할 지는 공급 제한 규칙에 따라 달라집니다. 보통은 API 엔드포인트마다 별도의 버킷을 둡니다.
- 사용자마다 하루에 1번의 포스팅, 150번의 친구추가, 5번의 좋아요를 제한해야 한다면 사용자마다 3개의 버킷이 필요합니다.
- IP 주소별로 처리율 제한을 적용해야 한다면 IP 주소마다 버킷을 하나씩 할당합니다.
- 시스템의 처리율을 초당 10,000개 요청으로 제한하고 싶다면, 모든 요청이 1개의 버킷을 공유하게 해야합니다.
- 장점
  - 간단하고 알고리즘에 대한 직관적인 이해가 쉽다.
  - 여러 기업이 보편적으로 사용하고 있다.(아마존, 스트라이프 등)
- 단점
  - 버킷 크기와 토큰 공급률의 적절한 값을 찾는 것이 어렵습니다.

#### 누출 버킷
![image](https://github.com/user-attachments/assets/54c67de2-3910-427d-ab5c-6f0ccb81fe31)

토큰 버킷 알고리즘과 비슷하지만 요청 처리율이 고정되어 있다는 차이점이 있습니다. 보통은 FIFO 큐로 구현합니다.
- 요청이 도착하면 큐가 가득찼는지 검사합니다. 빈자리가 있는 경우에는 큐에 요청을 추가합니다.
- 큐가 가득차면 요청은 버립니다.
- 지정된 시간마다 큐에서 요청을 꺼내어 처리합니다.

누출 버킷 또한 2가지 인자를 사용합니다.
1. 버킷 크기 : 큐 사이즈와 같은 값입니다.
2. 처리율 : 지정된 시간당 몇 개의 항목을 처리할지 지정하는 값입니다.

- 장점
  - 큐의 크기가 제한되어 있어 메모리 사용량 측면에서 효율적입니다.
  - 고정된 처리율을 갖고 있기 때문에 안정적 출력이 필요한 경우 적합합니다.
- 단점
  - 단시간에 많은 트래픽이 몰리는 경우 큐에는 오래된 요청들이 쌓이게 되고, 요청을 빠르게 처리하지 못하면 최신 요청이 버려집니다.
  - 누출 버킷 또한 2개의 인자의 적절한 값을 찾는 것이 어렵습니다.

#### 고정 윈도우 카운터
![image](https://github.com/user-attachments/assets/8706112e-5ed7-402e-8694-a6ce34cc0057)


타임라인을 고정된 간격의 윈도우로 나누고 각 윈도우마다 카운터를 붙입니다. 요청이 접수될 때마다 이 카운터의 값은 1씩 증가합니다.
카운터의 값이 사전에 설정된 임계치에 도달하면 새로운 요청은 새 윈도우가 열릴 때까지 버려집니다.

- 장점
  - 메모리 효율이 좋습니다. 윈도우마다 카운터 값만 저장하면 되기 때문입니다.
  - 직관적인 이해가 가능합니다. 복잡한 알고리즘이나 시간 계산이 없습니다.
  - 윈도가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴을 처리하기에 적합합니다. 
    - 시스템이 시간 단위 내 평탄한 트래픽 흐름을 중요시하는 경우 유용합니다.

- 단점
  - 윈도우 경계 부근에 순간적으로 많은 트래픽이 집중되는 경우 윈도우에 할당된 양보다 더 많은 요청이 처리될 수 있습니다. 예를 들어 카운터의 임계치가 5인데, 윈도우의 경계에서 각각 5개의 요청을 받으면 의도된 바와는 다르게 짧은 순간에 10개의 요청을 처리하게 된다.
    ![image](https://github.com/user-attachments/assets/568fdb51-df09-4e4c-a522-77c36540c1c0)

#### 이동 윈도우 로깅 알고리즘
이동 윈도우 로깅 알고리즘은 고정 윈도우 카운터 알고리즘이 가지는 문제를 해결할 수 있습니다.

이 알고리즘은 요청의 타임스탬프를 추적합니다. 타임스탬프는 보통 redis의 sorted set같은 캐시에 보관합니다.
새 요청이 들어오면 만료된 타임스탬프는 제거합니다. 현재 윈도우의 시작 지점보다 오래된 타임스탬프는 만료됩니다.
새 요청의 타임스탬프를 로그에 추가하고, 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달합니다.
그렇지 않을 경우 처리를 거부합니다.

![image](https://github.com/user-attachments/assets/07319971-3d63-44fd-ab2a-c0b56f9f9298)

보통 로그에 보관되는 값은 리눅스 타임스탬프를 사용합니다.
- 장점 : 처리율 제한 메커니즘이 정교하여, 어느 순간의 윈도우를 보더라도 허용되는 요청의 개수는 시스템 처리율 한도를 넘지 않는다.
- 단점 : 거부된 요청의 타임스탬프도 보관해야 하기 때문에 많은 메모리를 사용합니다.

#### 이동 윈도우 카운터 알고리즘
고정 윈도우 카운터와 이동 윈도우 로깅이 합쳐진 알고리즘입니다.

![image](https://github.com/user-attachments/assets/232ca4b9-3796-4263-a92d-bcec146f483e)

현재 1분간의 요청 수 + 직전 1분간의 요청 수 * 이동 윈도우와 직전 1분이 겹치는 비율을 계산합니다.
위 그림의 경우 6.5개로, 값은 보통 반올림이나 내림을 해서 사용합니다.
예제의 경우 1분당 요청 7개가 제한이었으니 현재 1분의 30%지점에 도착한 요청은 처리되지만, 이후로 도착하는 요청은 처리하지 않습니다.

#### 버킷 기반 이동 윈도우 카운터 알고리즘
책에 나와있는 내용은 현재 1분과 지난 1분에 걸친 영역의 퍼센트를 계산하는 방식이라면,
버킷 기반 이동 윈도우 카운터의 경우 윈도우 시간을 작은 버킷으로 나눕니다.

예를 들어 1시간동안 100개의 요청을 허용하는 처리율 제한기를 만든다고 가정했을 때, 버킷 크기를 20분으로 정했다면 1시간동안 3개의 버킷이 존재합니다.
02:00 ~ 03:00 구간을 고려할 경우 버킷은 02:00 ~ 02:20, 02:20 ~ 02:40, 02:40 ~ 03:00으로 나뉩니다.
각 버킷에 요청이 10개, 20개, 30개 있었다고 가정하겠습니다. 1시간동안 60개의 요청이 있으므로 아직 허용치입니다.
그러므로 02:50에 요청이 들어온다면 요청을 수락할 수 있습니다.

주의할 점은 02:50에 요청이 들어왔다면 01:50 ~ 02:50 사이에 있었던 요청을 고려해야하는데, 01:50~02:00이 누락되게 됩니다.
사전에 정해둔 버킷의 크기때문에 생기는 문제입니다.

만약 01:50 ~ 02:00에 트래픽이 급증해서 100건을 초과했었다면 사실 요청은 차단했어야 했던겁니다.
버킷의 크기를 조절함으로 이러한 오차를 어느정도 줄일 수 있습니다.

- 장점 : 개별 요청 로그를 저장하지 않아 메모리 사용량이 적습니다.
- 단점 : 엄격한 시간 단위로 정확히 제어하는 데 한계가 있습니다. 버킷을 작게 쪼갤수록 메모리 사용량이 늘어납니다.

### 나의 질문 : 트래픽이 폭증하는 경우 나머지 버킷에서 요청을 어떻게 받아야 할 것인가?
12:00 ~ 01:00 사이 요청을 감지한다고 했을 때, 12:00 ~ 12:10에 요청이 몰렸어도 나머지 시간에서 요청을 받게하고 싶다고 생각하여 검색을 해봤습니다.
근데 검색을 해도 제대로 설명해놓은 레퍼런스가 없었습니다.  
GPT의 경우, 이상치 버킷 무시(Outlier Bucket Filtering), 트래픽이 몰리는 곳은 낮은 가중치를 주는 가중치 부여 방식(Weig hted Sliding Window)등
데이터 분석이나 수학적 기법을 도입하는 얘기만 했습니다.  
근데 이 글을 작성하면서 갑자기 든 생각은
> 특정 시간에 트래픽이 몰리는 상황이 자주 발생하는 서비스라면, 다른 알고리즘을 사용하는 게 효율적이겠다.

였습니다. 윈도우 기반 알고리즘보다 토큰/누출 버킷 기반 알고리즘이 짧은 시간 버스트하는 트래픽에 대해 더 효율적인 것 같습니다.

의식의 흐름 죄송합니다..

### 개략적인 아키텍처
디스크까지 접근하는 경우 느리기 때문에 메모리상에서 동작하는 캐시에 카운터나 로그를 저장하는 게 바람직합니다.
심지어 시간에 기반한 만료 정책도 지원해주니 일석이조입니다.

![image](https://github.com/user-attachments/assets/30a3caeb-e3f4-4a1e-b5b2-6f9dd2bf4248) 

## 3단계 : 상세 설계
개략적인 아키텍처만으로는 
- 처리율 제한 규칙이 어떻게 만들어지고, 어디에 저장되는가?
- 처리가 제한된 요청은 어떻게 처리되는가?
같은 질문은 답하기가 어렵습니다.

![image](https://github.com/user-attachments/assets/7414d5b7-73da-48bc-a5bd-6798726809db)

- 처리율 제한 규칙의 경우 보통 디스크에 저장합니다. 작업 프로세스가 디스크에서 읽어 캐시에 저장합니다.
- 요청이 제한되면 API가 클라이언트에게는 HTTP 429 응답(too many request)을 보냅니다. 제한된 요청은 버리거나, 메세지큐에 보관했다가 나중에 처리할 수 있습니다.
- HTTP를 이용하는 경우 헤더를 사용하여 처리율과 관련한 값을 제어할 수 있습니다.
  - X-RateLimit-Remaining : 윈도우 내 남은 처리 가능 요청의 수
  - X-RateLimit-Limit : 매 윈도우마다 클라이언트가 전송할 수 있는 요청의 수
  - X-RateLimit-Retry-After : 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알림
  - 사용자의 요청이 많은 경우 429 오류를 X-RateLimit-Retry-After 헤더와 함께 반환합니다.

### 분산환경에서의 처리율 제한 장치의 구현
여러 대의 서버와 병렬 스레드를 지원하도록 시스템을 확장하는 것은 또 다른 문제입니다.
- 경쟁조건(race condition)
- 동기화(synchronization)

#### 경쟁조건(race condition)
![image](https://github.com/user-attachments/assets/2f0ae0aa-eafb-41f1-9830-c30f7dea6492)

카운터의 값이 의도한대로 오르지 않는 경우의 문제입니다. 락은 유명한 해결책이지만, 성능 저하 이슈가 있습니다.
이 문제를 해결하기 위한 다른 방법은 루아 스크립트와 레디스 자료구조인 정렬 집합을 사용하는 것입니다.

---

### 루아 스크립트?
Redis에서 제공하는 내장 스크립트 기능으로, 여러 Redis 명령어를 원자적으로 묶어서 실행할 수 있게 해주는 기능입니다.
여러 명령을 동시에 실행하면서도 중간에 다른 요청이 끼어들 수 없도록 보장합니다. 그러므로 경쟁 조건에서 동시성을 제어할 수 있습니다.

### 정렬 집합(sorted set)?
원소마다 점수(score) 를 부여하여 자동으로 정렬된 상태로 저장되는 집합(set) 형태입니다.
score를 timestamp로 저장하면 시간 기반 정렬이 쉬워져 sliding window 구현에 용이합니다.

---

#### 동기화(synchronization)
수백만 사용자를 지원하기 위해선 한 대의 처리율 제한 장치 서버로는 충분하지 않을 수 있습니다.
이 서버를 여러 대 두게 되면 동기화가 필요해집니다. 고정 세션을 사용하면 클라이언트의 요청을 항상 동일한 서버로 보낼 수 있지만,
확장성과 유연성을 고려하면 비추천합니다.
Redis와 같은 중앙 집중형 데이터 저장소를 사용하는 방법을 추천합니다.
![image](https://github.com/user-attachments/assets/a5bd18dc-9278-4440-b1aa-b033d63ddb04)

#### 성능최적화
여러 데이터 센터를 지원하는 문제는 처리율 제한 장치에 매우 중요한 문제입니다. 데이터 센터에서 멀리 떨어진 사용자를 지원하려다 보면
지연시간이 증가할 수 밖에 없기 때문입니다. 클라우드 서비스 사업자는 에지 서버를 세계 곳곳에 두고 지연시간을 줄입니다.

두 번째로 고려해야 할 것은 제한 장치 간에 데이터를 동기화할 때 최종 일관성 모델을 사용하는 것입니다.
6장에서 다룬다고 하여 상세하게 찾아보진 않겠습니다.

#### 모니터링
처리율 제한 장치를 설치한 이후에는 효과적으로 작동하는지 다음같은 항목을 확인해야 합니다.
- 채택한 알고리즘이 효과적인가?
- 정의한 처리율 제한 규칙이 효과적인가?

## 4단계 : 마무리
추가적인 논의를 해보면 좋은 주제를 정리하는 부분입니다.

#### 경성/연성
경성 처리율 제한 : 요청의 개수는 임계치를 절대 넘을 수 없습니다.
연성 처리율 제한 : 요청의 개수는 잠시 동안 임계치를 넘을 수 있습니다.

#### 다양한 계층에서의 처리
이번 장에서는 애플리케이션 계층에서의 처리율 제한에 대해 알아보았습니다. 다른 계층에서도 처리율 제한이 가능한데,
Iptables를 사용하면 IP주소에 처리율 제한을 걸 수 있습니다.

#### 처리율 제한을 회피하는 방법? 클라이언트를 어떻게 설계하는 것이 최선인가?
- 클라이언트 측 캐시를 사용하면 API 호출 횟수를 줄일 수 있습니다.
- 처리율 제한의 임계치를 이해하고 클라이언트 측에서도 임계치에 맞게 조절합니다.
- 예외나 에러를 처리하는 코드를 도입하여 클라이언트가 예외적 상황으로부터 복구될 수 있도록 합니다.
- 재시도 로직 구현 시 충분한 백오프 시간을 둡니다.

### 나의 질문 : 이걸 내가 직접 만들 일이 있을까?
[자바에서 사용하는 rate limiter](https://hogwart-scholars.tistory.com/entry/Spring-Boot-%EC%9E%90%EB%B0%94-%EC%8A%A4%ED%94%84%EB%A7%81%EC%97%90%EC%84%9C-%EC%B2%98%EB%A6%AC%EC%9C%A8-%EC%A0%9C%ED%95%9C-%EA%B8%B0%EB%8A%A5%EC%9D%84-%EA%B5%AC%ED%98%84%ED%95%98%EB%8A%94-4%EA%B0%80%EC%A7%80-%EB%B0%A9%EB%B2%95)

대비하라.
개인 프로젝트에 댓글 기능을 넣을 생각이니, 사용자가 하루에 달 수 있는 댓글 개수 제한을 두는 장치를 만들면 좋을듯 싶습니다.

### 나의 질문 : 모든 API 엔드포인트에 처리율 제한 장치를 구성해야 하나?
DoS 공격을 받는다고 가정하면, 모든 API는 공격 대상이 될 수 있으니, 모든 API에 대해 DoS 공격을 막는 
처리율 제한 장치를 일단 달아야 할까?
혹은 내 서비스가 흥해서 수억명의 사용자가 초당 수십억의 요청을 보내는 경우 어느 API에 대해서라도 과부하가 걸릴 수 있지 않을까?
그러니 basic한 처리 장치, 어느 API에 적용하더라도 문제가 없는, DoS 공격이나 수십억 요청에 대해서만 제한하는 장치를 모든 API에 장착시키면 좋지 않을까?

> 나의 결론  
> DoS 공격을 방어하는 데는 유용하지만, 대규모 트래픽 과부하 혹은 DDoS 공격 상황을 버티는 것은 처리율 제한 장치의 권한 밖이라고 생각한다.
> 즉 단일 대상으로부터 오는 요청 통제는 소개한 방식을 사용하면 좋지만, 트래픽이 몰리는 상황은
> load-balancing, Auto-scaling, 캐싱, CDN같은 방법을 사용하여 서버의 부하를 줄이는 것이 좋다.

### vs rate shaping(traffic shaping)
트래픽 셰이핑은 컴퓨터 네트워크의 통신량을 제어하여, 패킷을 지연시킴으로써 대역폭을 확보하고 통신 성능을 보장하거나 최적화 하는 일입니다.
패킷 셰이핑 이라고도 합니다. QoS(Quality of Service)를 향상 시키기 위해 사용합니다. 대역폭(bandwith) 관리와
네트워크 품질 보장을 목적으로 합니다.
토큰 버킷 혹은 리키 버킷(누출 버킷)이라는 알고리즘이 사용 가능합니다.
예를 들어, 동영상 스트리밍 도중 네트워크 환경이 좋지 않으면, 일시적으로 화질(전송률)을 낮출 때 사용합니다.

#### 차이점(GPT 피셜)
| 개념                  | 설명                                                   |
| ------------------- | ---------------------------------------------------- |
| **Rate Limiting**   | 요청 횟수의 최대치를 넘으면 거절 (ex. 초당 100건 초과 시 429 오류)         |
| **Rate Shaping**    | 요청은 받아들이되, 속도를 조절해서 처리 (ex. 큐에 쌓고 천천히 처리)            |
| **Traffic Shaping** | 네트워크 레벨에서 bandwidth 제한, QoS를 위한 조절 (네트워크 장비에서 자주 사용) |

Rate Limiting을 Traffic Policing이라고도 합니다. 임계치를 초과하는 요청은 거절하는 정책(Policing)을 사용한다는 의미입니다.
GPT의 경우 Rate shaping과 Traffic shaping을 구분해서 설명하는데, 막상 구글링해보면 Rate shaping이라는 말은 많이 사용하지 않는 것 같습니다.
보통은 두 단어를 섞어서 사용하는듯 싶습니다.
쓰고보니 처리율을 제한한다는 관점에서 두 주제 모두 저자가 다룬 느낌입니다...

> 결론   
> rate limiting : 임계치를 넘어서면 거절
> shaping : 임계치를 넘어서지 않게 네트워크나 데이터 전송 속도를 조절


### 참고
[FE에서의 스로틀링과 디바운싱](https://jins-dev.tistory.com/entry/%EC%9B%B9%ED%94%84%EB%A1%A0%ED%8A%B8%EC%97%94%EB%93%9C%EC%97%90%EC%84%9C-%EC%93%B0%EB%A1%9C%ED%8B%80%EB%A7%81Throttling%EA%B3%BC-%EB%94%94%EB%B0%94%EC%9A%B4%EC%8B%B1Debouncing%EC%9D%98-%EA%B0%9C%EB%85%90)

[이동 윈도우 카운터 알고리즘의 또다른 방식](https://medium.com/@saisandeepmopuri/system-design-rate-limiter-and-data-modelling-9304b0d18250)

[rate shaping(traffic shaping)](https://ko.wikipedia.org/wiki/%ED%8A%B8%EB%9E%98%ED%94%BD_%EC%85%B0%EC%9D%B4%ED%95%91)
